{"cells":[{"cell_type":"markdown","metadata":{"id":"0mlI5_rfcNMY"},"source":["A clone of this paper [Annotated Transformer](http://nlp.seas.harvard.edu/annotated-transformer/) with notes added by me.\n","\n","Alex Ambrioso (April 2022)\n","\n","The authors of the paper have implemented the orginal transformer from [Attention is All You Need](https://arxiv.org/pdf/1706.03762.pdf) with up-to-date libraries.  I am working through their implementation and adding some explanatory code and notes.  My goal is to understand this paper well enough so that if I were stranded on a desert island with enough compute I would be able to re-implement a transformer.\n","\n","***To run this file:***\n","\n","* Enable GPUs by changing the runtime type in the runtime menu.\n","* Turn on MyDrive.\n","* If necessary, remove vocab.pt in datasets file on MyDrive.  This file is created when a new vocabulary is built.\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13990,"status":"ok","timestamp":1723339197164,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"},"user_tz":-480},"id":"evvWCEj7QLGd","outputId":"7318c5f6-45c4-4080-c82f-85e9ddb0dec8","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting folium==0.2.1\n","  Downloading folium-0.2.1.tar.gz (69 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/70.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.0/70.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: Jinja2 in /usr/local/lib/python3.10/dist-packages (from folium==0.2.1) (3.1.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2->folium==0.2.1) (2.1.5)\n","Building wheels for collected packages: folium\n","  Building wheel for folium (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for folium: filename=folium-0.2.1-py3-none-any.whl size=79793 sha256=a324e647f0b6a572d4c3f2952f7a9fb4190e231b75a0c5d53ccf4842a18bb04b\n","  Stored in directory: /root/.cache/pip/wheels/00/0c/07/d7792a5444d5bb074361ac27da53cee9d5cce59a07fe9da5dd\n","Successfully built folium\n","Installing collected packages: folium\n","  Attempting uninstall: folium\n","    Found existing installation: folium 0.17.0\n","    Uninstalling folium-0.17.0:\n","      Successfully uninstalled folium-0.17.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.17.6 requires folium>=0.9.1, but you have folium 0.2.1 which is incompatible.\n","geemap 0.33.1 requires folium>=0.13.0, but you have folium 0.2.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed folium-0.2.1\n"]}],"source":["# This install was suggested by an error message generated when I did the earlier imports.   Apparently one of the\n","# packages was not compatible with the newer version of folium.\n","!pip install folium==0.2.1"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":105653,"status":"ok","timestamp":1723339302806,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"},"user_tz":-480},"id":"I2mv5V6ucgRH","outputId":"e5f68cd7-9f4d-4f97-cd85-b5cae496b48c","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m605.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m659.5/659.5 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","albumentations 1.4.13 requires pydantic>=2.7.0, but you have pydantic 1.8.2 which is incompatible.\n","en-core-web-sm 3.7.1 requires spacy<3.8.0,>=3.7.2, but you have spacy 3.2.0 which is incompatible.\n","torchaudio 2.3.1+cu121 requires torch==2.3.1, but you have torch 1.11.0 which is incompatible.\n","torchvision 0.18.1+cu121 requires torch==2.3.1, but you have torch 1.11.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m2024-08-11 01:21:25.393109: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-08-11 01:21:25.659491: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-08-11 01:21:25.704369: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-08-11 01:21:25.719355: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-08-11 01:21:26.838189: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[33mDEPRECATION: https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.2.0/de_core_news_sm-3.2.0-py3-none-any.whl#egg=de_core_news_sm==3.2.0 contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n","\u001b[0mCollecting de-core-news-sm==3.2.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.2.0/de_core_news_sm-3.2.0-py3-none-any.whl (19.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.2.0) (3.2.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.0.9)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (8.0.17)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (0.7.11)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (0.10.1)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.0.10)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (0.4.2)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (0.11.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (4.66.5)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.26.4)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.8.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.1.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (71.0.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (24.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.4.0)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.2.0)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (6.4.0)\n","Requirement already satisfied: pathlib-abc==0.1.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (0.1.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2024.7.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (8.1.7)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.1.5)\n","Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.2.0)\n","Installing collected packages: de-core-news-sm\n","Successfully installed de-core-news-sm-3.2.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('de_core_news_sm')\n","2024-08-11 01:21:34.699824: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-08-11 01:21:34.731405: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-08-11 01:21:34.740951: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-08-11 01:21:34.762003: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-08-11 01:21:36.341689: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[33mDEPRECATION: https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl#egg=en_core_web_sm==3.2.0 contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n","\u001b[0mCollecting en-core-web-sm==3.2.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.2.0) (3.2.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.9)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.17)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.11)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.10.1)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.10)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.2)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.11.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.66.5)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.4)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.1.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (71.0.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (24.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.4.0)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.2.0)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (6.4.0)\n","Requirement already satisfied: pathlib-abc==0.1.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.1.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2024.7.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.1.7)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.1.5)\n","Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.2.0)\n","Installing collected packages: en-core-web-sm\n","  Attempting uninstall: en-core-web-sm\n","    Found existing installation: en-core-web-sm 3.7.1\n","    Uninstalling en-core-web-sm-3.7.1:\n","      Successfully uninstalled en-core-web-sm-3.7.1\n","Successfully installed en-core-web-sm-3.2.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n"]}],"source":["!pip install -q torchdata==0.3.0 torchtext==0.12 spacy==3.2 altair GPUtil\n","# For new language translation will need to download vocabulary.\n","# Note that I have used two different sources.\n","!python -m spacy download de_core_news_sm\n","!python -m spacy download en_core_web_sm"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"tTWWeP35dXNh","executionInfo":{"status":"ok","timestamp":1723339311507,"user_tz":-480,"elapsed":8708,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"outputs":[],"source":["import os\n","from os.path import exists\n","import torch\n","import torch.nn as nn\n","from torch.nn.functional import log_softmax, pad\n","# See: https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n","# See: https://pytorch.org/docs/stable/generated/torch.nn.functional.pad.html\n","import math\n","import copy\n","import time\n","from torch.optim.lr_scheduler import LambdaLR\n","import pandas as pd\n","import altair as alt\n","from torchtext.data.functional import to_map_style_dataset\n","from torch.utils.data import DataLoader\n","from torchtext.vocab import build_vocab_from_iterator\n","import torchtext.datasets as datasets\n","import spacy\n","import GPUtil\n","import warnings\n","from torch.utils.data.distributed import DistributedSampler\n","import torch.distributed as dist\n","import torch.multiprocessing as mp\n","from torch.nn.parallel import DistributedDataParallel as DDP\n","\n","\n","# Set to False to skip notebook execution (e.g. for debugging)\n","warnings.filterwarnings(\"ignore\")\n","RUN_EXAMPLES = True"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"NFp45u0Jd0aB","executionInfo":{"status":"ok","timestamp":1723339311508,"user_tz":-480,"elapsed":10,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"outputs":[],"source":["# Some convenience helper functions used throughout the notebook\n","\n","\n","def is_interactive_notebook():\n","    return __name__ == \"__main__\"\n","\n","\n","def show_example(fn, args=[]):\n","    if __name__ == \"__main__\" and RUN_EXAMPLES:\n","        return fn(*args)\n","\n","\n","def execute_example(fn, args=[]):\n","    if __name__ == \"__main__\" and RUN_EXAMPLES:\n","        fn(*args)\n","\n","\n","class DummyOptimizer(torch.optim.Optimizer):\n","    def __init__(self):\n","        self.param_groups = [{\"lr\": 0}]\n","        None\n","\n","    def step(self):\n","        None\n","\n","    def zero_grad(self, set_to_none=False):\n","        None\n","\n","\n","class DummyScheduler:\n","    def step(self):\n","        None"]},{"cell_type":"markdown","metadata":{"id":"FXSobPzveYTN"},"source":["# From Section:  Background\n","These comments are from the original paper:  [Attention is All You Need](https://arxiv.org/pdf/1706.03762.pdf)\n","\"In these models, the number of operations required to relate signals from two arbitrary input or output positions grows in the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes it more difficult to learn dependencies between distant positions. In the Transformer this is reduced to a constant number of operations, albeit at the cost of reduced effective resolution due to averaging attention-weighted positions, an effect we counteract with Multi-Head Attention.\"\n","\n","\"Self-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence.\"\n","\n","\"To the best of our knowledge, however, the Transformer is the first transduction model relying entirely on self-attention to compute representations of its input and output without using sequence aligned RNNs or convolution.\""]},{"cell_type":"markdown","metadata":{"id":"Tvnz6S61fkag"},"source":["# From Section:  Model Architecture\n","\"Most competitive neural sequence transduction models have an encoder-decoder structure (cite). Here, the encoder maps an input sequence of symbol representations $(x_1, ..., x_n)$ to a sequence of continuous representations $\\mathbf{z} = (z_1, ..., z_n)$. Given $\\mathbf{z}$, the decoder then generates an output sequence $(y_1,...,y_m)$ of symbols one element at a time. At each step the model is auto-regressive (cite), consuming the previously generated symbols as additional input when generating the next.\""]},{"cell_type":"code","execution_count":5,"metadata":{"id":"vp--QFs1f-KR","executionInfo":{"status":"ok","timestamp":1723339313014,"user_tz":-480,"elapsed":35,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"outputs":[],"source":["class EncoderDecoder(nn.Module):\n","    \"\"\"\n","    A standard Encoder-Decoder architecture. Base for this and many\n","    other models.\n","    \"\"\"\n","\n","    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n","        super(EncoderDecoder, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.src_embed = src_embed\n","        self.tgt_embed = tgt_embed\n","        self.generator = generator\n","\n","    def forward(self, src, tgt, src_mask, tgt_mask):\n","        \"Take in and process masked src and target sequences.\"\n","        return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask)\n","\n","    def encode(self, src, src_mask):\n","        return self.encoder(self.src_embed(src), src_mask)\n","\n","    def decode(self, memory, src_mask, tgt, tgt_mask):\n","        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\n","\n","\n","class Generator(nn.Module):\n","    \"Define standard linear + softmax generation step.\"\n","\n","    def __init__(self, d_model, vocab):\n","        super(Generator, self).__init__()\n","        # See: https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n","        self.proj = nn.Linear(d_model, vocab)\n","\n","    def forward(self, x):\n","        return log_softmax(self.proj(x), dim=-1)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"_8-_vaaVf-9L","executionInfo":{"status":"ok","timestamp":1723339313015,"user_tz":-480,"elapsed":35,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"outputs":[],"source":["class Generator(nn.Module):\n","    \"Define standard linear + softmax generation step.\"\n","\n","    def __init__(self, d_model, vocab):\n","        super(Generator, self).__init__()\n","        self.proj = nn.Linear(d_model, vocab)\n","\n","    def forward(self, x):\n","        # See https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html\n","        return log_softmax(self.proj(x), dim=-1)"]},{"cell_type":"markdown","metadata":{"id":"8hCeFYn6NUSa"},"source":["# Example code illustrating Softmax and Logsoftmax.\n","\n","See [Softmax vs LogSoftMax](\"https://medium.com/@AbhiramiVS/softmax-vs-logsoftmax-eb94254445a2\")."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1723339313015,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"},"user_tz":-480},"id":"L325cgtPNbtb","outputId":"4ed64723-abc9-4b1a-f8ee-63e01a67b789"},"outputs":[{"output_type":"stream","name":"stdout","text":["input = tensor([[0.2726, 0.6561, 0.4071],\n","        [0.6883, 0.9219, 0.8083],\n","        [0.8453, 0.0089, 0.2674]])\n","Softmax(input) = tensor([[0.2769, 0.4063, 0.3168],\n","        [0.2949, 0.3725, 0.3325],\n","        [0.5014, 0.2173, 0.2813]])\n","LogSoftmax(input) = tensor([[-1.2841, -0.9006, -1.1496],\n","        [-1.2211, -0.9874, -1.1010],\n","        [-0.6903, -1.5267, -1.2682]])\n","Log(Softmax)) = tensor([[-1.2841, -0.9006, -1.1496],\n","        [-1.2211, -0.9874, -1.1010],\n","        [-0.6903, -1.5267, -1.2682]])\n"]}],"source":["input = torch.rand(3,3)\n","print(f\"input = {input}\")\n","SM = nn.Softmax(dim=1)\n","LSM = nn.LogSoftmax(dim=1)\n","print(f\"Softmax(input) = {SM(input)}\") # We calculuate the softmax with the nn library function.\n","print(f\"LogSoftmax(input) = {LSM(input)}\")\n","print(f\"Log(Softmax)) = {torch.log(SM(input))}\") # We use the torch.log function to take the log of the matrix.\n"]},{"cell_type":"code","source":["torch.nn"],"metadata":{"id":"mkWxFjk3dSAe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722941947176,"user_tz":-480,"elapsed":15,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}},"outputId":"4c912448-9488-4c01-a2bc-7ddfc07c3eea"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<module 'torch.nn' from '/usr/local/lib/python3.10/dist-packages/torch/nn/__init__.py'>"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"fRypCCYRhkTU"},"source":["# Example code illustrating the Linear class (my notes)\n","See: https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n","This code illustrates how nn.Linear works.   The example code applies a linear transformation to the input data (input) in several different ways.  We start by using nn.Linear to generate a random initialization of the weight and bias.\n","\n","Then we check by using the weight and bias methods of nn.Linear to access the values from the initialization and recompute the output matrix (new_output) using matrix operations.  Then we adjust the weight and bias, apply linear again, and check.  Finally, we do the last computation again using the forward method."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1723339313016,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"},"user_tz":-480},"id":"v2_9gmqThv9i","outputId":"8c9b03e5-2dde-4d89-ab1b-f246e08c9e1c"},"outputs":[{"output_type":"stream","name":"stdout","text":["input = tensor([[1., 2., 3.],\n","        [4., 5., 6.],\n","        [7., 8., 9.]])\n","output size = <built-in method size of Tensor object at 0x7a1c87181cb0>\n","output = tensor([[-1.8479,  0.2016, -1.9022],\n","        [-3.5160, -0.4313, -3.5841],\n","        [-5.1841, -1.0643, -5.2660]], grad_fn=<AddmmBackward0>)\n","transform.weight = Parameter containing:\n","tensor([[-0.0991, -0.1795, -0.2775],\n","        [ 0.0930, -0.4818,  0.1779],\n","        [ 0.1865, -0.5009, -0.2462]], requires_grad=True)\n","transform.bias = Parameter containing:\n","tensor([-0.5575,  0.5386, -0.3481], requires_grad=True)\n","computation check = tensor([[-1.8479,  0.2016, -1.9022],\n","        [-3.5160, -0.4313, -3.5841],\n","        [-5.1841, -1.0643, -5.2660]], grad_fn=<AddBackward0>)\n","transform.weight = Parameter containing:\n","tensor([[-1.8479,  0.2016, -1.9022],\n","        [-3.5160, -0.4313, -3.5841],\n","        [-5.1841, -1.0643, -5.2660]], requires_grad=True)\n","transform.bias = Parameter containing:\n","tensor([[0.5000, 0.5000, 0.5000]], requires_grad=True)\n","new_output = tensor([[ 7.5737, 13.7279, 19.8821],\n","        [13.7279, 25.8939, 38.0600],\n","        [19.8821, 38.0600, 56.2378]], grad_fn=<AddmmBackward0>)\n","computation check = tensor([[ 7.5737, 13.7279, 19.8821],\n","        [13.7279, 25.8939, 38.0600],\n","        [19.8821, 38.0600, 56.2378]], grad_fn=<AddBackward0>)\n","transform.forward(output) = tensor([[ 7.5737, 13.7279, 19.8821],\n","        [13.7279, 25.8939, 38.0600],\n","        [19.8821, 38.0600, 56.2378]], grad_fn=<AddmmBackward0>)\n"]}],"source":["# First we apply an transformation to input using an initial transformation.\n","data = [[1., 2., 3.], [4., 5., 6.], [7.,8.,9.]]\n","input = torch.tensor(data) # input matrix\n","transform = nn.Linear(3,3) # create transform\n","output = transform(input) # apply the transform\n","print(f\"input = {input}\")\n","print(f\"output size = {output.size}\")\n","print(f\"output = {output}\")\n","print(f\"transform.weight = {transform.weight}\")\n","print(f\"transform.bias = {transform.bias}\")\n","print(f\"computation check = {torch.matmul(input, torch.t(transform.weight)) + transform.bias}\")\n","# Now we set a new weight and bias.   Note that these are set as Parameters, a special tensor.\n","# See https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html.\n","transform.weight = nn.Parameter(output)\n","transform.bias = nn.Parameter(torch.tensor([[0.5, 0.5, 0.5]]))\n","new_output = transform(output)\n","print(f\"transform.weight = {transform.weight}\")\n","print(f\"transform.bias = {transform.bias}\")\n","# Note that the following matrices are all the same.\n","print(f\"new_output = {new_output}\")\n","print(f\"computation check = {torch.matmul(output, torch.t(transform.weight)) + transform.bias}\")\n","# Finally we illustrate the forward method of Linear.\n","print(f\"transform.forward(output) = {transform.forward(output)}\")\n","\n"]},{"cell_type":"markdown","source":["Need to investigate the role the copy.deepcopy()\n","\n","---\n","\n","method."],"metadata":{"id":"dMXrhElHn4k-"}},{"cell_type":"code","execution_count":9,"metadata":{"id":"x0u4yjjak2-N","executionInfo":{"status":"ok","timestamp":1723339313016,"user_tz":-480,"elapsed":27,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"outputs":[],"source":["def clones(module, N):\n","    \"Produce N identical layers.\"\n","    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"R1AVhAhO1URS","executionInfo":{"status":"ok","timestamp":1723339313016,"user_tz":-480,"elapsed":26,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"outputs":[],"source":["class Encoder(nn.Module):\n","    \"Core encoder is a stack of N layers\"\n","\n","    def __init__(self, layer, N):\n","        super(Encoder, self).__init__()\n","        self.layers = clones(layer, N)\n","        self.norm = LayerNorm(layer.size)\n","\n","    def forward(self, x, mask):\n","        \"Pass the input (and mask) through each layer in turn.\"\n","        for layer in self.layers:\n","            x = layer(x, mask)\n","        return self.norm(x)"]},{"cell_type":"markdown","metadata":{"id":"9WxCKph92nYk"},"source":["# Start with Layer Normalization\n","\n","\"We employ a residual connection around each of the two sub-layers, followed by layer normalization.\"\n","\n","For paper on residual connections see:\n","[Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)\n","\n","For paper on layer normalization see: [Layer Normalization](https://arxiv.org/abs/1607.06450)\n","\n","For paper on batch normalization see: [Batch Normalizaton](https://arxiv.org/abs/1502.03167)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"np2hNOK72tYE","executionInfo":{"status":"ok","timestamp":1723339313018,"user_tz":-480,"elapsed":27,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"outputs":[],"source":["class LayerNorm(nn.Module):\n","    \"Construct a layernorm module (See citation for details).\"\n","\n","    def __init__(self, features, eps=1e-6):\n","        super(LayerNorm, self).__init__()\n","        self.a_2 = nn.Parameter(torch.ones(features))\n","        self.b_2 = nn.Parameter(torch.zeros(features))\n","        self.eps = eps\n","\n","    def forward(self, x):\n","        mean = x.mean(-1, keepdim=True)\n","        std = x.std(-1, keepdim=True)\n","        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n"]},{"cell_type":"markdown","metadata":{"id":"pEhq7hEZNMhR"},"source":["\"Each layer has two sub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-wise fully connected feed-forward network.\""]},{"cell_type":"code","execution_count":12,"metadata":{"id":"cAI3B-bYNKF6","executionInfo":{"status":"ok","timestamp":1723339313018,"user_tz":-480,"elapsed":26,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"outputs":[],"source":["class SublayerConnection(nn.Module):\n","    \"\"\"\n","    A residual connection followed by a layer norm.\n","    Note for code simplicity the norm is first as opposed to last.\n","    \"\"\"\n","\n","    def __init__(self, size, dropout):\n","        super(SublayerConnection, self).__init__()\n","        self.norm = LayerNorm(size)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, sublayer):\n","        \"Apply residual connection to any sublayer with the same size.\"\n","        return x + self.dropout(sublayer(self.norm(x)))"]},{"cell_type":"markdown","metadata":{"id":"NLj7QxocN7P6"},"source":["Each layer has two sub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-wise fully connected feed-forward network."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"PaCL-yqWN7rb","executionInfo":{"status":"ok","timestamp":1723339313019,"user_tz":-480,"elapsed":26,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"outputs":[],"source":["class EncoderLayer(nn.Module):\n","    \"Encoder is made up of self-attn and feed forward (defined below)\"\n","\n","    def __init__(self, size, self_attn, feed_forward, dropout):\n","        super(EncoderLayer, self).__init__()\n","        self.self_attn = self_attn\n","        self.feed_forward = feed_forward\n","        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n","        self.size = size\n","\n","    def forward(self, x, mask):\n","        \"Follow Figure 1 (left) for connections.\"\n","        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n","        return self.sublayer[1](x, self.feed_forward)"]},{"cell_type":"markdown","metadata":{"id":"8In8ioRhOoU3"},"source":["The decoder is also composed of a stack of $N=6$ identical layers."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"IsCOra5qOzvo","executionInfo":{"status":"ok","timestamp":1723339313020,"user_tz":-480,"elapsed":26,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"outputs":[],"source":["class Decoder(nn.Module):\n","    \"Generic N layer decoder with masking.\"\n","\n","    def __init__(self, layer, N):\n","        super(Decoder, self).__init__()\n","        self.layers = clones(layer, N)\n","        self.norm = LayerNorm(layer.size)\n","\n","    def forward(self, x, memory, src_mask, tgt_mask):\n","        for layer in self.layers:\n","            x = layer(x, memory, src_mask, tgt_mask)\n","        return self.norm(x)"]},{"cell_type":"markdown","metadata":{"id":"hr-iQ2JGPK7k"},"source":["In addition to the two sub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head attention over the output of the encoder stack. Similar to the encoder, we employ residual connections around each of the sub-layers, followed by layer normalization."]},{"cell_type":"code","execution_count":15,"metadata":{"id":"HG-VLG5mPPqb","executionInfo":{"status":"ok","timestamp":1723339313020,"user_tz":-480,"elapsed":25,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"outputs":[],"source":["class DecoderLayer(nn.Module):\n","    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n","\n","    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n","        super(DecoderLayer, self).__init__()\n","        self.size = size\n","        self.self_attn = self_attn\n","        self.src_attn = src_attn\n","        self.feed_forward = feed_forward\n","        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n","\n","    def forward(self, x, memory, src_mask, tgt_mask):\n","        \"Follow Figure 1 (right) for connections.\"\n","        m = memory\n","        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n","        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n","        return self.sublayer[2](x, self.feed_forward)"]},{"cell_type":"markdown","metadata":{"id":"XWoxOVyFPfF0"},"source":["We also modify the self-attention sub-layer in the decoder stack to prevent positions from attending to subsequent positions. This masking, combined with fact that the output embeddings are offset by one position, ensures that the predictions for position $i$ can depend only on the known outputs at positions less than $i$."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"HbBrmfrrPVLQ","executionInfo":{"status":"ok","timestamp":1723339313021,"user_tz":-480,"elapsed":25,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"outputs":[],"source":["def subsequent_mask(size):\n","    \"Mask out subsequent positions.\"\n","    attn_shape = (1, size, size)\n","    subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(\n","        torch.uint8\n","    )\n","    return subsequent_mask == 0"]},{"cell_type":"markdown","metadata":{"id":"nhkwtIR9PtEW"},"source":["Below the attention mask shows the position each tgt word (row) is allowed to look at (column). Words are blocked for attending to future words during training."]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":309},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1723339313021,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"},"user_tz":-480},"id":"bLA_2C2hPjpy","outputId":"a91403fd-b652-4466-940d-501824aa22fe"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","<div id=\"altair-viz-0bb20ab80f9e4b0ab3e6ab819eb663cf\"></div>\n","<script type=\"text/javascript\">\n","  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n","  (function(spec, embedOpt){\n","    let outputDiv = document.currentScript.previousElementSibling;\n","    if (outputDiv.id !== \"altair-viz-0bb20ab80f9e4b0ab3e6ab819eb663cf\") {\n","      outputDiv = document.getElementById(\"altair-viz-0bb20ab80f9e4b0ab3e6ab819eb663cf\");\n","    }\n","    const paths = {\n","      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n","      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n","      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n","      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n","    };\n","\n","    function maybeLoadScript(lib, version) {\n","      var key = `${lib.replace(\"-\", \"\")}_version`;\n","      return (VEGA_DEBUG[key] == version) ?\n","        Promise.resolve(paths[lib]) :\n","        new Promise(function(resolve, reject) {\n","          var s = document.createElement('script');\n","          document.getElementsByTagName(\"head\")[0].appendChild(s);\n","          s.async = true;\n","          s.onload = () => {\n","            VEGA_DEBUG[key] = version;\n","            return resolve(paths[lib]);\n","          };\n","          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n","          s.src = paths[lib];\n","        });\n","    }\n","\n","    function showError(err) {\n","      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n","      throw err;\n","    }\n","\n","    function displayChart(vegaEmbed) {\n","      vegaEmbed(outputDiv, spec, embedOpt)\n","        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n","    }\n","\n","    if(typeof define === \"function\" && define.amd) {\n","      requirejs.config({paths});\n","      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n","    } else {\n","      maybeLoadScript(\"vega\", \"5\")\n","        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n","        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n","        .catch(showError)\n","        .then(() => displayChart(vegaEmbed));\n","    }\n","  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-9521fd308f9833e12c73f8e2e1a22793\"}, \"mark\": \"rect\", \"encoding\": {\"color\": {\"field\": \"Subsequent Mask\", \"scale\": {\"scheme\": \"viridis\"}, \"type\": \"quantitative\"}, \"x\": {\"field\": \"Window\", \"type\": \"ordinal\"}, \"y\": {\"field\": \"Masking\", \"type\": \"ordinal\"}}, \"height\": 250, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"width\": 250, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-9521fd308f9833e12c73f8e2e1a22793\": [{\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 0}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 1}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 2}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 3}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 1, \"Masking\": 0}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 1}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 2}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 3}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 2, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 2, \"Masking\": 1}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 2}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 3}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 3, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 3, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 3, \"Masking\": 2}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 3}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 4, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 4, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 4, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 4, \"Masking\": 3}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 5, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 5, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 5, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 5, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 5, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 9}]}}, {\"mode\": \"vega-lite\"});\n","</script>"],"text/plain":["alt.Chart(...)"]},"metadata":{},"execution_count":17}],"source":["max_pos = 10\n","def example_mask():\n","    LS_data = pd.concat(\n","        [\n","            pd.DataFrame(\n","                {\n","                    \"Subsequent Mask\": subsequent_mask(max_pos)[0][x, y].flatten(),\n","                    \"Window\": y,\n","                    \"Masking\": x,\n","                }\n","            )\n","            for y in range(max_pos)\n","            for x in range(max_pos)\n","        ]\n","    )\n","\n","    return (\n","        alt.Chart(LS_data)\n","        .mark_rect()\n","        .properties(height=250, width=250)\n","        .encode(\n","            alt.X(\"Window:O\"),\n","            alt.Y(\"Masking:O\"),\n","            alt.Color(\"Subsequent Mask:Q\", scale=alt.Scale(scheme=\"viridis\")),\n","        )\n","        .interactive()\n","    )\n","\n","\n","show_example(example_mask)"]},{"cell_type":"markdown","metadata":{"id":"WjeqN_DdSgB5"},"source":["# Attention\n","\n","We call our particular attention “Scaled Dot-Product Attention”. The input consists of queries and keys of dimension $d_k$, and values of dimension $d_v$. We compute the dot products of the query with all keys, divide each by $\\sqrt{d_k}$ , and apply a softmax function to obtain the weights on the values.\n"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"6pUfAgd8P2FK","executionInfo":{"status":"ok","timestamp":1723339313021,"user_tz":-480,"elapsed":20,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"outputs":[],"source":["def attention(query, key, value, mask=None, dropout=None):\n","    \"Compute 'Scaled Dot Product Attention'\"\n","    d_k = query.size(-1)\n","    # Here is the attention function\n","    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n","    if mask is not None:\n","        scores = scores.masked_fill(mask == 0, -1e9)\n","    p_attn = scores.softmax(dim=-1)\n","    if dropout is not None:\n","        p_attn = dropout(p_attn)\n","    return torch.matmul(p_attn, value), p_attn"]},{"cell_type":"markdown","metadata":{"id":"r7SkQ19FV_tV"},"source":["# Multi-head Attention\n","\n","\"Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions.\"\n","\n","\"In this work we employ $h=8$ parallel attention layers, or heads. For each of these we use $d_k=d_v=d_{\\text{model}}/h=64$ due to the reduced dimension of each head, the total computational cost is similar to that of single-head attention with full dimensionality.\"\n","\n","\n","***Note that for Latex in markdown we simply need to surround the equation with \\\\$ as follows \\\\$equation\\\\$. Also to escape \\\\$ we use \\\\\\\\.***\n","\n","\n"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"2BTw2ZacSRqE","executionInfo":{"status":"ok","timestamp":1723339313021,"user_tz":-480,"elapsed":18,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"outputs":[],"source":["class MultiHeadedAttention(nn.Module):\n","    def __init__(self, h, d_model, dropout=0.1):\n","        \"Take in model size and number of heads.\"\n","        super(MultiHeadedAttention, self).__init__()\n","        assert d_model % h == 0\n","        # We assume d_v always equals d_k\n","        self.d_k = d_model // h\n","        self.h = h\n","        self.linears = clones(nn.Linear(d_model, d_model), 4)\n","        self.attn = None\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","    def forward(self, query, key, value, mask=None):\n","        \"Implements Figure 2\"\n","        if mask is not None:\n","            # Same mask applied to all h heads.\n","            mask = mask.unsqueeze(1)\n","        nbatches = query.size(0)\n","\n","        # 1) Do all the linear projections in batch from d_model => h x d_k\n","        query, key, value = [\n","            lin(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n","            for lin, x in zip(self.linears, (query, key, value))\n","        ]\n","\n","        # 2) Apply attention on all the projected vectors in batch.\n","        x, self.attn = attention(\n","            query, key, value, mask=mask, dropout=self.dropout\n","        )\n","\n","        # 3) \"Concat\" using a view and apply a final linear.\n","        x = (\n","            x.transpose(1, 2)\n","            .contiguous()\n","            .view(nbatches, -1, self.h * self.d_k)\n","        )\n","        del query\n","        del key\n","        del value\n","        return self.linears[-1](x)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"-SJUtJvpWBC4","executionInfo":{"status":"ok","timestamp":1723339313022,"user_tz":-480,"elapsed":18,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"outputs":[],"source":["class PositionwiseFeedForward(nn.Module):\n","    \"Implements FFN equation.\"\n","\n","    def __init__(self, d_model, d_ff, dropout=0.1):\n","        super(PositionwiseFeedForward, self).__init__()\n","        self.w_1 = nn.Linear(d_model, d_ff)\n","        self.w_2 = nn.Linear(d_ff, d_model)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        return self.w_2(self.dropout(self.w_1(x).relu()))"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"CU229IlZXnLr","executionInfo":{"status":"ok","timestamp":1723339313022,"user_tz":-480,"elapsed":17,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"outputs":[],"source":["class Embeddings(nn.Module):\n","    def __init__(self, d_model, vocab):\n","        super(Embeddings, self).__init__()\n","        self.lut = nn.Embedding(vocab, d_model)\n","        self.d_model = d_model\n","\n","    def forward(self, x):\n","        return self.lut(x) * math.sqrt(self.d_model)"]},{"cell_type":"markdown","metadata":{"id":"85902mYNOqRU"},"source":["Since the transformer has no recurrence and no convolution some information about position needs to be introduced.   The transformer uses positional embeddings for this purpose.\n","\n","In the paper the authors state that:\n","\n","\"We chose this function because we hypothesized it would allow the model to easily learn to attend by relative positions, since for any fixed offset $k$, $PE_{pos+k}$ can be represented as a linear function of $PE_{pos}$.\"\n","\n","This linear function follows from a standard trigonometric identity.   See [Fourier Series]( https://en.wikipedia.org/wiki/Fourier_series) (Eq. 3)."]},{"cell_type":"code","execution_count":22,"metadata":{"id":"LBxQI_pKXqYC","executionInfo":{"status":"ok","timestamp":1723339313022,"user_tz":-480,"elapsed":17,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"outputs":[],"source":["class PositionalEncoding(nn.Module):\n","    \"Implement the PE function.\"\n","\n","    def __init__(self, d_model, dropout, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        # Compute the positional encodings once in log space.\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len).unsqueeze(1)\n","        div_term = torch.exp(\n","            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n","        )\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer(\"pe\", pe)\n","\n","    def forward(self, x):\n","        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n","        return self.dropout(x)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":388},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1723339313473,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"},"user_tz":-480},"id":"rMnFDzajXv7C","outputId":"1a597290-010a-4551-d2e7-d16aee62bc28"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","<div id=\"altair-viz-290414301be74372908c2faa67d9c41f\"></div>\n","<script type=\"text/javascript\">\n","  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n","  (function(spec, embedOpt){\n","    let outputDiv = document.currentScript.previousElementSibling;\n","    if (outputDiv.id !== \"altair-viz-290414301be74372908c2faa67d9c41f\") {\n","      outputDiv = document.getElementById(\"altair-viz-290414301be74372908c2faa67d9c41f\");\n","    }\n","    const paths = {\n","      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n","      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n","      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n","      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n","    };\n","\n","    function maybeLoadScript(lib, version) {\n","      var key = `${lib.replace(\"-\", \"\")}_version`;\n","      return (VEGA_DEBUG[key] == version) ?\n","        Promise.resolve(paths[lib]) :\n","        new Promise(function(resolve, reject) {\n","          var s = document.createElement('script');\n","          document.getElementsByTagName(\"head\")[0].appendChild(s);\n","          s.async = true;\n","          s.onload = () => {\n","            VEGA_DEBUG[key] = version;\n","            return resolve(paths[lib]);\n","          };\n","          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n","          s.src = paths[lib];\n","        });\n","    }\n","\n","    function showError(err) {\n","      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n","      throw err;\n","    }\n","\n","    function displayChart(vegaEmbed) {\n","      vegaEmbed(outputDiv, spec, embedOpt)\n","        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n","    }\n","\n","    if(typeof define === \"function\" && define.amd) {\n","      requirejs.config({paths});\n","      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n","    } else {\n","      maybeLoadScript(\"vega\", \"5\")\n","        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n","        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n","        .catch(showError)\n","        .then(() => displayChart(vegaEmbed));\n","    }\n","  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-eafc635ddfa311c913cbcc2d2bc4477d\"}, \"mark\": \"line\", \"encoding\": {\"color\": {\"field\": \"dimension\", \"type\": \"nominal\"}, \"x\": {\"field\": \"position\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"embedding\", \"type\": \"quantitative\"}}, \"selection\": {\"selector002\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-eafc635ddfa311c913cbcc2d2bc4477d\": [{\"embedding\": 0.0, \"dimension\": 4, \"position\": 0}, {\"embedding\": 0.15782663226127625, \"dimension\": 4, \"position\": 1}, {\"embedding\": 0.3116971552371979, \"dimension\": 4, \"position\": 2}, {\"embedding\": 0.45775455236434937, \"dimension\": 4, \"position\": 3}, {\"embedding\": 0.5923377275466919, \"dimension\": 4, \"position\": 4}, {\"embedding\": 0.7120732069015503, \"dimension\": 4, \"position\": 5}, {\"embedding\": 0.813959538936615, \"dimension\": 4, \"position\": 6}, {\"embedding\": 0.8954429626464844, \"dimension\": 4, \"position\": 7}, {\"embedding\": 0.9544808864593506, \"dimension\": 4, \"position\": 8}, {\"embedding\": 0.989593505859375, \"dimension\": 4, \"position\": 9}, {\"embedding\": 0.9999006390571594, \"dimension\": 4, \"position\": 10}, {\"embedding\": 0.9851439595222473, \"dimension\": 4, \"position\": 11}, {\"embedding\": 0.94569331407547, \"dimension\": 4, \"position\": 12}, {\"embedding\": 0.8825376033782959, \"dimension\": 4, \"position\": 13}, {\"embedding\": 0.7972599267959595, \"dimension\": 4, \"position\": 14}, {\"embedding\": 0.6919978260993958, \"dimension\": 4, \"position\": 15}, {\"embedding\": 0.5693899393081665, \"dimension\": 4, \"position\": 16}, {\"embedding\": 0.4325096309185028, \"dimension\": 4, \"position\": 17}, {\"embedding\": 0.284787654876709, \"dimension\": 4, \"position\": 18}, {\"embedding\": 0.12992730736732483, \"dimension\": 4, \"position\": 19}, {\"embedding\": -0.028190065175294876, \"dimension\": 4, \"position\": 20}, {\"embedding\": -0.18560057878494263, \"dimension\": 4, \"position\": 21}, {\"embedding\": -0.3383587896823883, \"dimension\": 4, \"position\": 22}, {\"embedding\": -0.4826357960700989, \"dimension\": 4, \"position\": 23}, {\"embedding\": -0.6148146390914917, \"dimension\": 4, \"position\": 24}, {\"embedding\": -0.7315824031829834, \"dimension\": 4, \"position\": 25}, {\"embedding\": -0.8300122618675232, \"dimension\": 4, \"position\": 26}, {\"embedding\": -0.9076365828514099, \"dimension\": 4, \"position\": 27}, {\"embedding\": -0.96250981092453, \"dimension\": 4, \"position\": 28}, {\"embedding\": -0.9932565093040466, \"dimension\": 4, \"position\": 29}, {\"embedding\": -0.9991058707237244, \"dimension\": 4, \"position\": 30}, {\"embedding\": -0.9799113273620605, \"dimension\": 4, \"position\": 31}, {\"embedding\": -0.9361540079116821, \"dimension\": 4, \"position\": 32}, {\"embedding\": -0.8689308166503906, \"dimension\": 4, \"position\": 33}, {\"embedding\": -0.7799267172813416, \"dimension\": 4, \"position\": 34}, {\"embedding\": -0.6713724136352539, \"dimension\": 4, \"position\": 35}, {\"embedding\": -0.5459895133972168, \"dimension\": 4, \"position\": 36}, {\"embedding\": -0.40692076086997986, \"dimension\": 4, \"position\": 37}, {\"embedding\": -0.2576519548892975, \"dimension\": 4, \"position\": 38}, {\"embedding\": -0.10192479938268661, \"dimension\": 4, \"position\": 39}, {\"embedding\": 0.056357722729444504, \"dimension\": 4, \"position\": 40}, {\"embedding\": 0.21322709321975708, \"dimension\": 4, \"position\": 41}, {\"embedding\": 0.3647516369819641, \"dimension\": 4, \"position\": 42}, {\"embedding\": 0.5071332454681396, \"dimension\": 4, \"position\": 43}, {\"embedding\": 0.6368028521537781, \"dimension\": 4, \"position\": 44}, {\"embedding\": 0.7505101561546326, \"dimension\": 4, \"position\": 45}, {\"embedding\": 0.8454052805900574, \"dimension\": 4, \"position\": 46}, {\"embedding\": 0.9191088080406189, \"dimension\": 4, \"position\": 47}, {\"embedding\": 0.9697737693786621, \"dimension\": 4, \"position\": 48}, {\"embedding\": 0.9961300492286682, \"dimension\": 4, \"position\": 49}, {\"embedding\": 0.9975170493125916, \"dimension\": 4, \"position\": 50}, {\"embedding\": 0.9738998413085938, \"dimension\": 4, \"position\": 51}, {\"embedding\": 0.9258706569671631, \"dimension\": 4, \"position\": 52}, {\"embedding\": 0.8546332716941833, \"dimension\": 4, \"position\": 53}, {\"embedding\": 0.7619734406471252, \"dimension\": 4, \"position\": 54}, {\"embedding\": 0.6502137184143066, \"dimension\": 4, \"position\": 55}, {\"embedding\": 0.5221555233001709, \"dimension\": 4, \"position\": 56}, {\"embedding\": 0.38100889325141907, \"dimension\": 4, \"position\": 57}, {\"embedding\": 0.23031172156333923, \"dimension\": 4, \"position\": 58}, {\"embedding\": 0.07384055852890015, \"dimension\": 4, \"position\": 59}, {\"embedding\": -0.08448058366775513, \"dimension\": 4, \"position\": 60}, {\"embedding\": -0.2406841218471527, \"dimension\": 4, \"position\": 61}, {\"embedding\": -0.3908545970916748, \"dimension\": 4, \"position\": 62}, {\"embedding\": -0.5312277674674988, \"dimension\": 4, \"position\": 63}, {\"embedding\": -0.6582850813865662, \"dimension\": 4, \"position\": 64}, {\"embedding\": -0.768841564655304, \"dimension\": 4, \"position\": 65}, {\"embedding\": -0.8601260781288147, \"dimension\": 4, \"position\": 66}, {\"embedding\": -0.9298503994941711, \"dimension\": 4, \"position\": 67}, {\"embedding\": -0.9762668013572693, \"dimension\": 4, \"position\": 68}, {\"embedding\": -0.9982118010520935, \"dimension\": 4, \"position\": 69}, {\"embedding\": -0.9951352477073669, \"dimension\": 4, \"position\": 70}, {\"embedding\": -0.967114269733429, \"dimension\": 4, \"position\": 71}, {\"embedding\": -0.9148513078689575, \"dimension\": 4, \"position\": 72}, {\"embedding\": -0.839656412601471, \"dimension\": 4, \"position\": 73}, {\"embedding\": -0.7434144616127014, \"dimension\": 4, \"position\": 74}, {\"embedding\": -0.6285378336906433, \"dimension\": 4, \"position\": 75}, {\"embedding\": -0.4979061186313629, \"dimension\": 4, \"position\": 76}, {\"embedding\": -0.3547937273979187, \"dimension\": 4, \"position\": 77}, {\"embedding\": -0.20278796553611755, \"dimension\": 4, \"position\": 78}, {\"embedding\": -0.04569905996322632, \"dimension\": 4, \"position\": 79}, {\"embedding\": 0.11253630369901657, \"dimension\": 4, \"position\": 80}, {\"embedding\": 0.2679498493671417, \"dimension\": 4, \"position\": 81}, {\"embedding\": 0.4166468679904938, \"dimension\": 4, \"position\": 82}, {\"embedding\": 0.5549001097679138, \"dimension\": 4, \"position\": 83}, {\"embedding\": 0.6792440414428711, \"dimension\": 4, \"position\": 84}, {\"embedding\": 0.7865618467330933, \"dimension\": 4, \"position\": 85}, {\"embedding\": 0.8741634488105774, \"dimension\": 4, \"position\": 86}, {\"embedding\": 0.9398530125617981, \"dimension\": 4, \"position\": 87}, {\"embedding\": 0.9819839596748352, \"dimension\": 4, \"position\": 88}, {\"embedding\": 0.9995002150535583, \"dimension\": 4, \"position\": 89}, {\"embedding\": 0.9919626712799072, \"dimension\": 4, \"position\": 90}, {\"embedding\": 0.959559977054596, \"dimension\": 4, \"position\": 91}, {\"embedding\": 0.903104841709137, \"dimension\": 4, \"position\": 92}, {\"embedding\": 0.8240122199058533, \"dimension\": 4, \"position\": 93}, {\"embedding\": 0.7242646217346191, \"dimension\": 4, \"position\": 94}, {\"embedding\": 0.6063624024391174, \"dimension\": 4, \"position\": 95}, {\"embedding\": 0.4732609689235687, \"dimension\": 4, \"position\": 96}, {\"embedding\": 0.32829657196998596, \"dimension\": 4, \"position\": 97}, {\"embedding\": 0.17510302364826202, \"dimension\": 4, \"position\": 98}, {\"embedding\": 0.01752028614282608, \"dimension\": 4, \"position\": 99}, {\"embedding\": 1.0, \"dimension\": 5, \"position\": 0}, {\"embedding\": 0.9874668121337891, \"dimension\": 5, \"position\": 1}, {\"embedding\": 0.9501814842224121, \"dimension\": 5, \"position\": 2}, {\"embedding\": 0.8890786170959473, \"dimension\": 5, \"position\": 3}, {\"embedding\": 0.8056897521018982, \"dimension\": 5, \"position\": 4}, {\"embedding\": 0.7021052241325378, \"dimension\": 5, \"position\": 5}, {\"embedding\": 0.5809215903282166, \"dimension\": 5, \"position\": 6}, {\"embedding\": 0.44517630338668823, \"dimension\": 5, \"position\": 7}, {\"embedding\": 0.2982720732688904, \"dimension\": 5, \"position\": 8}, {\"embedding\": 0.14389123022556305, \"dimension\": 5, \"position\": 9}, {\"embedding\": -0.01409643329679966, \"dimension\": 5, \"position\": 10}, {\"embedding\": -0.1717306226491928, \"dimension\": 5, \"position\": 11}, {\"embedding\": -0.32506027817726135, \"dimension\": 5, \"position\": 12}, {\"embedding\": -0.47024187445640564, \"dimension\": 5, \"position\": 13}, {\"embedding\": -0.6036361455917358, \"dimension\": 5, \"position\": 14}, {\"embedding\": -0.7218996286392212, \"dimension\": 5, \"position\": 15}, {\"embedding\": -0.8220675587654114, \"dimension\": 5, \"position\": 16}, {\"embedding\": -0.9016293287277222, \"dimension\": 5, \"position\": 17}, {\"embedding\": -0.9585906267166138, \"dimension\": 5, \"position\": 18}, {\"embedding\": -0.9915235042572021, \"dimension\": 5, \"position\": 19}, {\"embedding\": -0.9996025562286377, \"dimension\": 5, \"position\": 20}, {\"embedding\": -0.9826252460479736, \"dimension\": 5, \"position\": 21}, {\"embedding\": -0.941017210483551, \"dimension\": 5, \"position\": 22}, {\"embedding\": -0.8758211731910706, \"dimension\": 5, \"position\": 23}, {\"embedding\": -0.788671612739563, \"dimension\": 5, \"position\": 24}, {\"embedding\": -0.6817529797554016, \"dimension\": 5, \"position\": 25}, {\"embedding\": -0.5577451586723328, \"dimension\": 5, \"position\": 26}, {\"embedding\": -0.4197568893432617, \"dimension\": 5, \"position\": 27}, {\"embedding\": -0.27124688029289246, \"dimension\": 5, \"position\": 28}, {\"embedding\": -0.11593768745660782, \"dimension\": 5, \"position\": 29}, {\"embedding\": 0.042278096079826355, \"dimension\": 5, \"position\": 30}, {\"embedding\": 0.19943365454673767, \"dimension\": 5, \"position\": 31}, {\"embedding\": 0.3515901565551758, \"dimension\": 5, \"position\": 32}, {\"embedding\": 0.4949335753917694, \"dimension\": 5, \"position\": 33}, {\"embedding\": 0.6258708238601685, \"dimension\": 5, \"position\": 34}, {\"embedding\": 0.7411201596260071, \"dimension\": 5, \"position\": 35}, {\"embedding\": 0.8377919793128967, \"dimension\": 5, \"position\": 36}, {\"embedding\": 0.9134634733200073, \"dimension\": 5, \"position\": 37}, {\"embedding\": 0.9662377834320068, \"dimension\": 5, \"position\": 38}, {\"embedding\": 0.994792103767395, \"dimension\": 5, \"position\": 39}, {\"embedding\": 0.9984106421470642, \"dimension\": 5, \"position\": 40}, {\"embedding\": 0.9770026803016663, \"dimension\": 5, \"position\": 41}, {\"embedding\": 0.931104838848114, \"dimension\": 5, \"position\": 42}, {\"embedding\": 0.8618676662445068, \"dimension\": 5, \"position\": 43}, {\"embedding\": 0.7710266709327698, \"dimension\": 5, \"position\": 44}, {\"embedding\": 0.6608588695526123, \"dimension\": 5, \"position\": 45}, {\"embedding\": 0.5341253876686096, \"dimension\": 5, \"position\": 46}, {\"embedding\": 0.3940037488937378, \"dimension\": 5, \"position\": 47}, {\"embedding\": 0.24400585889816284, \"dimension\": 5, \"position\": 48}, {\"embedding\": 0.08789165318012238, \"dimension\": 5, \"position\": 49}, {\"embedding\": -0.07042567431926727, \"dimension\": 5, \"position\": 50}, {\"embedding\": -0.2269781529903412, \"dimension\": 5, \"position\": 51}, {\"embedding\": -0.37784066796302795, \"dimension\": 5, \"position\": 52}, {\"embedding\": -0.5192320942878723, \"dimension\": 5, \"position\": 53}, {\"embedding\": -0.6476082801818848, \"dimension\": 5, \"position\": 54}, {\"embedding\": -0.7597513794898987, \"dimension\": 5, \"position\": 55}, {\"embedding\": -0.8528502583503723, \"dimension\": 5, \"position\": 56}, {\"embedding\": -0.9245713949203491, \"dimension\": 5, \"position\": 57}, {\"embedding\": -0.973116934299469, \"dimension\": 5, \"position\": 58}, {\"embedding\": -0.9972700476646423, \"dimension\": 5, \"position\": 59}, {\"embedding\": -0.9964250922203064, \"dimension\": 5, \"position\": 60}, {\"embedding\": -0.9706035256385803, \"dimension\": 5, \"position\": 61}, {\"embedding\": -0.9204524159431458, \"dimension\": 5, \"position\": 62}, {\"embedding\": -0.8472290635108948, \"dimension\": 5, \"position\": 63}, {\"embedding\": -0.7527687549591064, \"dimension\": 5, \"position\": 64}, {\"embedding\": -0.6394393444061279, \"dimension\": 5, \"position\": 65}, {\"embedding\": -0.5100815296173096, \"dimension\": 5, \"position\": 66}, {\"embedding\": -0.3679378628730774, \"dimension\": 5, \"position\": 67}, {\"embedding\": -0.2165713608264923, \"dimension\": 5, \"position\": 68}, {\"embedding\": -0.05977622792124748, \"dimension\": 5, \"position\": 69}, {\"embedding\": 0.09851823002099991, \"dimension\": 5, \"position\": 70}, {\"embedding\": 0.254342257976532, \"dimension\": 5, \"position\": 71}, {\"embedding\": 0.4037908613681793, \"dimension\": 5, \"position\": 72}, {\"embedding\": 0.543117880821228, \"dimension\": 5, \"position\": 73}, {\"embedding\": 0.6688309907913208, \"dimension\": 5, \"position\": 74}, {\"embedding\": 0.7777789831161499, \"dimension\": 5, \"position\": 75}, {\"embedding\": 0.8672309517860413, \"dimension\": 5, \"position\": 76}, {\"embedding\": 0.9349446296691895, \"dimension\": 5, \"position\": 77}, {\"embedding\": 0.9792226552963257, \"dimension\": 5, \"position\": 78}, {\"embedding\": 0.998955249786377, \"dimension\": 5, \"position\": 79}, {\"embedding\": 0.9936476349830627, \"dimension\": 5, \"position\": 80}, {\"embedding\": 0.9634328484535217, \"dimension\": 5, \"position\": 81}, {\"embedding\": 0.9090684056282043, \"dimension\": 5, \"position\": 82}, {\"embedding\": 0.8319169878959656, \"dimension\": 5, \"position\": 83}, {\"embedding\": 0.733912467956543, \"dimension\": 5, \"position\": 84}, {\"embedding\": 0.617511510848999, \"dimension\": 5, \"position\": 85}, {\"embedding\": 0.4856317937374115, \"dimension\": 5, \"position\": 86}, {\"embedding\": 0.3415791094303131, \"dimension\": 5, \"position\": 87}, {\"embedding\": 0.18896427750587463, \"dimension\": 5, \"position\": 88}, {\"embedding\": 0.0316128134727478, \"dimension\": 5, \"position\": 89}, {\"embedding\": -0.12653106451034546, \"dimension\": 5, \"position\": 90}, {\"embedding\": -0.28150418400764465, \"dimension\": 5, \"position\": 91}, {\"embedding\": -0.4294200837612152, \"dimension\": 5, \"position\": 92}, {\"embedding\": -0.5665720105171204, \"dimension\": 5, \"position\": 93}, {\"embedding\": -0.6895220875740051, \"dimension\": 5, \"position\": 94}, {\"embedding\": -0.7951884269714355, \"dimension\": 5, \"position\": 95}, {\"embedding\": -0.880922257900238, \"dimension\": 5, \"position\": 96}, {\"embedding\": -0.9445747137069702, \"dimension\": 5, \"position\": 97}, {\"embedding\": -0.9845501184463501, \"dimension\": 5, \"position\": 98}, {\"embedding\": -0.9998465180397034, \"dimension\": 5, \"position\": 99}, {\"embedding\": 0.0, \"dimension\": 6, \"position\": 0}, {\"embedding\": 0.06305388361215591, \"dimension\": 6, \"position\": 1}, {\"embedding\": 0.12585683166980743, \"dimension\": 6, \"position\": 2}, {\"embedding\": 0.18815888464450836, \"dimension\": 6, \"position\": 3}, {\"embedding\": 0.24971213936805725, \"dimension\": 6, \"position\": 4}, {\"embedding\": 0.31027159094810486, \"dimension\": 6, \"position\": 5}, {\"embedding\": 0.3695962131023407, \"dimension\": 6, \"position\": 6}, {\"embedding\": 0.4274499714374542, \"dimension\": 6, \"position\": 7}, {\"embedding\": 0.4836025834083557, \"dimension\": 6, \"position\": 8}, {\"embedding\": 0.5378305912017822, \"dimension\": 6, \"position\": 9}, {\"embedding\": 0.5899181365966797, \"dimension\": 6, \"position\": 10}, {\"embedding\": 0.6396579146385193, \"dimension\": 6, \"position\": 11}, {\"embedding\": 0.6868520379066467, \"dimension\": 6, \"position\": 12}, {\"embedding\": 0.7313126921653748, \"dimension\": 6, \"position\": 13}, {\"embedding\": 0.7728629112243652, \"dimension\": 6, \"position\": 14}, {\"embedding\": 0.8113372921943665, \"dimension\": 6, \"position\": 15}, {\"embedding\": 0.8465827703475952, \"dimension\": 6, \"position\": 16}, {\"embedding\": 0.8784590363502502, \"dimension\": 6, \"position\": 17}, {\"embedding\": 0.9068393111228943, \"dimension\": 6, \"position\": 18}, {\"embedding\": 0.9316105246543884, \"dimension\": 6, \"position\": 19}, {\"embedding\": 0.9526742100715637, \"dimension\": 6, \"position\": 20}, {\"embedding\": 0.9699464440345764, \"dimension\": 6, \"position\": 21}, {\"embedding\": 0.9833585619926453, \"dimension\": 6, \"position\": 22}, {\"embedding\": 0.9928570985794067, \"dimension\": 6, \"position\": 23}, {\"embedding\": 0.9984043836593628, \"dimension\": 6, \"position\": 24}, {\"embedding\": 0.999978244304657, \"dimension\": 6, \"position\": 25}, {\"embedding\": 0.9975724220275879, \"dimension\": 6, \"position\": 26}, {\"embedding\": 0.9911965131759644, \"dimension\": 6, \"position\": 27}, {\"embedding\": 0.9808759093284607, \"dimension\": 6, \"position\": 28}, {\"embedding\": 0.9666516780853271, \"dimension\": 6, \"position\": 29}, {\"embedding\": 0.9485803842544556, \"dimension\": 6, \"position\": 30}, {\"embedding\": 0.9267339110374451, \"dimension\": 6, \"position\": 31}, {\"embedding\": 0.9011994004249573, \"dimension\": 6, \"position\": 32}, {\"embedding\": 0.8720782399177551, \"dimension\": 6, \"position\": 33}, {\"embedding\": 0.8394865393638611, \"dimension\": 6, \"position\": 34}, {\"embedding\": 0.8035537600517273, \"dimension\": 6, \"position\": 35}, {\"embedding\": 0.7644230127334595, \"dimension\": 6, \"position\": 36}, {\"embedding\": 0.7222501039505005, \"dimension\": 6, \"position\": 37}, {\"embedding\": 0.6772029399871826, \"dimension\": 6, \"position\": 38}, {\"embedding\": 0.6294605135917664, \"dimension\": 6, \"position\": 39}, {\"embedding\": 0.57921302318573, \"dimension\": 6, \"position\": 40}, {\"embedding\": 0.5266605615615845, \"dimension\": 6, \"position\": 41}, {\"embedding\": 0.4720119535923004, \"dimension\": 6, \"position\": 42}, {\"embedding\": 0.41548484563827515, \"dimension\": 6, \"position\": 43}, {\"embedding\": 0.3573042154312134, \"dimension\": 6, \"position\": 44}, {\"embedding\": 0.29770180583000183, \"dimension\": 6, \"position\": 45}, {\"embedding\": 0.23691439628601074, \"dimension\": 6, \"position\": 46}, {\"embedding\": 0.17518411576747894, \"dimension\": 6, \"position\": 47}, {\"embedding\": 0.1127568930387497, \"dimension\": 6, \"position\": 48}, {\"embedding\": 0.04988069087266922, \"dimension\": 6, \"position\": 49}, {\"embedding\": -0.013194027356803417, \"dimension\": 6, \"position\": 50}, {\"embedding\": -0.07621623575687408, \"dimension\": 6, \"position\": 51}, {\"embedding\": -0.1389348804950714, \"dimension\": 6, \"position\": 52}, {\"embedding\": -0.20110084116458893, \"dimension\": 6, \"position\": 53}, {\"embedding\": -0.2624664604663849, \"dimension\": 6, \"position\": 54}, {\"embedding\": -0.3227875530719757, \"dimension\": 6, \"position\": 55}, {\"embedding\": -0.3818237781524658, \"dimension\": 6, \"position\": 56}, {\"embedding\": -0.4393406808376312, \"dimension\": 6, \"position\": 57}, {\"embedding\": -0.49510911107063293, \"dimension\": 6, \"position\": 58}, {\"embedding\": -0.5489069223403931, \"dimension\": 6, \"position\": 59}, {\"embedding\": -0.6005204319953918, \"dimension\": 6, \"position\": 60}, {\"embedding\": -0.6497439742088318, \"dimension\": 6, \"position\": 61}, {\"embedding\": -0.6963817477226257, \"dimension\": 6, \"position\": 62}, {\"embedding\": -0.7402478456497192, \"dimension\": 6, \"position\": 63}, {\"embedding\": -0.7811681628227234, \"dimension\": 6, \"position\": 64}, {\"embedding\": -0.8189795017242432, \"dimension\": 6, \"position\": 65}, {\"embedding\": -0.8535317182540894, \"dimension\": 6, \"position\": 66}, {\"embedding\": -0.8846868872642517, \"dimension\": 6, \"position\": 67}, {\"embedding\": -0.9123212099075317, \"dimension\": 6, \"position\": 68}, {\"embedding\": -0.936324954032898, \"dimension\": 6, \"position\": 69}, {\"embedding\": -0.956602156162262, \"dimension\": 6, \"position\": 70}, {\"embedding\": -0.9730724096298218, \"dimension\": 6, \"position\": 71}, {\"embedding\": -0.9856699705123901, \"dimension\": 6, \"position\": 72}, {\"embedding\": -0.9943448305130005, \"dimension\": 6, \"position\": 73}, {\"embedding\": -0.9990625381469727, \"dimension\": 6, \"position\": 74}, {\"embedding\": -0.9998041391372681, \"dimension\": 6, \"position\": 75}, {\"embedding\": -0.9965668320655823, \"dimension\": 6, \"position\": 76}, {\"embedding\": -0.9893633723258972, \"dimension\": 6, \"position\": 77}, {\"embedding\": -0.9782225489616394, \"dimension\": 6, \"position\": 78}, {\"embedding\": -0.963188648223877, \"dimension\": 6, \"position\": 79}, {\"embedding\": -0.9443213939666748, \"dimension\": 6, \"position\": 80}, {\"embedding\": -0.9216960668563843, \"dimension\": 6, \"position\": 81}, {\"embedding\": -0.8954026699066162, \"dimension\": 6, \"position\": 82}, {\"embedding\": -0.8655455708503723, \"dimension\": 6, \"position\": 83}, {\"embedding\": -0.8322440981864929, \"dimension\": 6, \"position\": 84}, {\"embedding\": -0.795630156993866, \"dimension\": 6, \"position\": 85}, {\"embedding\": -0.7558501362800598, \"dimension\": 6, \"position\": 86}, {\"embedding\": -0.7130619883537292, \"dimension\": 6, \"position\": 87}, {\"embedding\": -0.6674357056617737, \"dimension\": 6, \"position\": 88}, {\"embedding\": -0.6191535592079163, \"dimension\": 6, \"position\": 89}, {\"embedding\": -0.5684073567390442, \"dimension\": 6, \"position\": 90}, {\"embedding\": -0.5153986215591431, \"dimension\": 6, \"position\": 91}, {\"embedding\": -0.46033912897109985, \"dimension\": 6, \"position\": 92}, {\"embedding\": -0.40344759821891785, \"dimension\": 6, \"position\": 93}, {\"embedding\": -0.3449500501155853, \"dimension\": 6, \"position\": 94}, {\"embedding\": -0.28508007526397705, \"dimension\": 6, \"position\": 95}, {\"embedding\": -0.22407560050487518, \"dimension\": 6, \"position\": 96}, {\"embedding\": -0.1621788740158081, \"dimension\": 6, \"position\": 97}, {\"embedding\": -0.09963719546794891, \"dimension\": 6, \"position\": 98}, {\"embedding\": -0.03669850528240204, \"dimension\": 6, \"position\": 99}, {\"embedding\": 1.0, \"dimension\": 7, \"position\": 0}, {\"embedding\": 0.9980100989341736, \"dimension\": 7, \"position\": 1}, {\"embedding\": 0.9920483827590942, \"dimension\": 7, \"position\": 2}, {\"embedding\": 0.9821385741233826, \"dimension\": 7, \"position\": 3}, {\"embedding\": 0.9683201313018799, \"dimension\": 7, \"position\": 4}, {\"embedding\": 0.9506479501724243, \"dimension\": 7, \"position\": 5}, {\"embedding\": 0.9291924834251404, \"dimension\": 7, \"position\": 6}, {\"embedding\": 0.9040390253067017, \"dimension\": 7, \"position\": 7}, {\"embedding\": 0.8752877116203308, \"dimension\": 7, \"position\": 8}, {\"embedding\": 0.8430529236793518, \"dimension\": 7, \"position\": 9}, {\"embedding\": 0.8074630498886108, \"dimension\": 7, \"position\": 10}, {\"embedding\": 0.7686597108840942, \"dimension\": 7, \"position\": 11}, {\"embedding\": 0.7267972826957703, \"dimension\": 7, \"position\": 12}, {\"embedding\": 0.6820423603057861, \"dimension\": 7, \"position\": 13}, {\"embedding\": 0.6345730423927307, \"dimension\": 7, \"position\": 14}, {\"embedding\": 0.5845783352851868, \"dimension\": 7, \"position\": 15}, {\"embedding\": 0.532257080078125, \"dimension\": 7, \"position\": 16}, {\"embedding\": 0.47781768441200256, \"dimension\": 7, \"position\": 17}, {\"embedding\": 0.4214765727519989, \"dimension\": 7, \"position\": 18}, {\"embedding\": 0.36345821619033813, \"dimension\": 7, \"position\": 19}, {\"embedding\": 0.30399325489997864, \"dimension\": 7, \"position\": 20}, {\"embedding\": 0.243318572640419, \"dimension\": 7, \"position\": 21}, {\"embedding\": 0.18167544901371002, \"dimension\": 7, \"position\": 22}, {\"embedding\": 0.11930941045284271, \"dimension\": 7, \"position\": 23}, {\"embedding\": 0.056468550115823746, \"dimension\": 7, \"position\": 24}, {\"embedding\": -0.006597157102078199, \"dimension\": 7, \"position\": 25}, {\"embedding\": -0.06963648647069931, \"dimension\": 7, \"position\": 26}, {\"embedding\": -0.1323987990617752, \"dimension\": 7, \"position\": 27}, {\"embedding\": -0.1946340948343277, \"dimension\": 7, \"position\": 28}, {\"embedding\": -0.25609490275382996, \"dimension\": 7, \"position\": 29}, {\"embedding\": -0.31653639674186707, \"dimension\": 7, \"position\": 30}, {\"embedding\": -0.37571826577186584, \"dimension\": 7, \"position\": 31}, {\"embedding\": -0.43340474367141724, \"dimension\": 7, \"position\": 32}, {\"embedding\": -0.4893665015697479, \"dimension\": 7, \"position\": 33}, {\"embedding\": -0.5433804988861084, \"dimension\": 7, \"position\": 34}, {\"embedding\": -0.5952321887016296, \"dimension\": 7, \"position\": 35}, {\"embedding\": -0.6447150111198425, \"dimension\": 7, \"position\": 36}, {\"embedding\": -0.6916319727897644, \"dimension\": 7, \"position\": 37}, {\"embedding\": -0.7357962727546692, \"dimension\": 7, \"position\": 38}, {\"embedding\": -0.7770324349403381, \"dimension\": 7, \"position\": 39}, {\"embedding\": -0.8151761889457703, \"dimension\": 7, \"position\": 40}, {\"embedding\": -0.8500756621360779, \"dimension\": 7, \"position\": 41}, {\"embedding\": -0.8815921545028687, \"dimension\": 7, \"position\": 42}, {\"embedding\": -0.9096000790596008, \"dimension\": 7, \"position\": 43}, {\"embedding\": -0.933988094329834, \"dimension\": 7, \"position\": 44}, {\"embedding\": -0.9546589255332947, \"dimension\": 7, \"position\": 45}, {\"embedding\": -0.971530556678772, \"dimension\": 7, \"position\": 46}, {\"embedding\": -0.9845356941223145, \"dimension\": 7, \"position\": 47}, {\"embedding\": -0.9936226010322571, \"dimension\": 7, \"position\": 48}, {\"embedding\": -0.998755156993866, \"dimension\": 7, \"position\": 49}, {\"embedding\": -0.9999129772186279, \"dimension\": 7, \"position\": 50}, {\"embedding\": -0.9970912933349609, \"dimension\": 7, \"position\": 51}, {\"embedding\": -0.9903014898300171, \"dimension\": 7, \"position\": 52}, {\"embedding\": -0.9795705676078796, \"dimension\": 7, \"position\": 53}, {\"embedding\": -0.964941143989563, \"dimension\": 7, \"position\": 54}, {\"embedding\": -0.9464714527130127, \"dimension\": 7, \"position\": 55}, {\"embedding\": -0.9242351651191711, \"dimension\": 7, \"position\": 56}, {\"embedding\": -0.8983205556869507, \"dimension\": 7, \"position\": 57}, {\"embedding\": -0.8688308000564575, \"dimension\": 7, \"position\": 58}, {\"embedding\": -0.8358834981918335, \"dimension\": 7, \"position\": 59}, {\"embedding\": -0.7996094226837158, \"dimension\": 7, \"position\": 60}, {\"embedding\": -0.7601531147956848, \"dimension\": 7, \"position\": 61}, {\"embedding\": -0.7176715731620789, \"dimension\": 7, \"position\": 62}, {\"embedding\": -0.6723340749740601, \"dimension\": 7, \"position\": 63}, {\"embedding\": -0.6243206262588501, \"dimension\": 7, \"position\": 64}, {\"embedding\": -0.5738227963447571, \"dimension\": 7, \"position\": 65}, {\"embedding\": -0.5210408568382263, \"dimension\": 7, \"position\": 66}, {\"embedding\": -0.46618568897247314, \"dimension\": 7, \"position\": 67}, {\"embedding\": -0.4094752371311188, \"dimension\": 7, \"position\": 68}, {\"embedding\": -0.3511347472667694, \"dimension\": 7, \"position\": 69}, {\"embedding\": -0.2913972735404968, \"dimension\": 7, \"position\": 70}, {\"embedding\": -0.23049965500831604, \"dimension\": 7, \"position\": 71}, {\"embedding\": -0.1686851680278778, \"dimension\": 7, \"position\": 72}, {\"embedding\": -0.10619935393333435, \"dimension\": 7, \"position\": 73}, {\"embedding\": -0.04329042136669159, \"dimension\": 7, \"position\": 74}, {\"embedding\": 0.019790323451161385, \"dimension\": 7, \"position\": 75}, {\"embedding\": 0.08279230445623398, \"dimension\": 7, \"position\": 76}, {\"embedding\": 0.14546526968479156, \"dimension\": 7, \"position\": 77}, {\"embedding\": 0.20755885541439056, \"dimension\": 7, \"position\": 78}, {\"embedding\": 0.2688263952732086, \"dimension\": 7, \"position\": 79}, {\"embedding\": 0.3290245532989502, \"dimension\": 7, \"position\": 80}, {\"embedding\": 0.3879128098487854, \"dimension\": 7, \"position\": 81}, {\"embedding\": 0.4452572762966156, \"dimension\": 7, \"position\": 82}, {\"embedding\": 0.5008301138877869, \"dimension\": 7, \"position\": 83}, {\"embedding\": 0.5544094443321228, \"dimension\": 7, \"position\": 84}, {\"embedding\": 0.605782687664032, \"dimension\": 7, \"position\": 85}, {\"embedding\": 0.6547446846961975, \"dimension\": 7, \"position\": 86}, {\"embedding\": 0.7011010050773621, \"dimension\": 7, \"position\": 87}, {\"embedding\": 0.7446674108505249, \"dimension\": 7, \"position\": 88}, {\"embedding\": 0.7852699160575867, \"dimension\": 7, \"position\": 89}, {\"embedding\": 0.8227472901344299, \"dimension\": 7, \"position\": 90}, {\"embedding\": 0.856950581073761, \"dimension\": 7, \"position\": 91}, {\"embedding\": 0.8877431154251099, \"dimension\": 7, \"position\": 92}, {\"embedding\": 0.9150027632713318, \"dimension\": 7, \"position\": 93}, {\"embedding\": 0.9386210441589355, \"dimension\": 7, \"position\": 94}, {\"embedding\": 0.9585037231445312, \"dimension\": 7, \"position\": 95}, {\"embedding\": 0.9745717644691467, \"dimension\": 7, \"position\": 96}, {\"embedding\": 0.9867613911628723, \"dimension\": 7, \"position\": 97}, {\"embedding\": 0.9950238466262817, \"dimension\": 7, \"position\": 98}, {\"embedding\": 0.9993264079093933, \"dimension\": 7, \"position\": 99}]}}, {\"mode\": \"vega-lite\"});\n","</script>"],"text/plain":["alt.Chart(...)"]},"metadata":{},"execution_count":23}],"source":["def example_positional():\n","    pe = PositionalEncoding(20, 0)\n","    y = pe.forward(torch.zeros(1, 100, 20))\n","\n","    data = pd.concat(\n","        [\n","            pd.DataFrame(\n","                {\n","                    \"embedding\": y[0, :, dim],\n","                    \"dimension\": dim,\n","                    \"position\": list(range(100)),\n","                }\n","            )\n","            for dim in [4, 5, 6, 7]\n","        ]\n","    )\n","\n","    return (\n","        alt.Chart(data)\n","        .mark_line()\n","        .properties(width=800)\n","        .encode(x=\"position\", y=\"embedding\", color=\"dimension:N\")\n","        .interactive()\n","    )\n","\n","\n","show_example(example_positional)"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"vSpXguJ8X1Cs","executionInfo":{"status":"ok","timestamp":1723339313473,"user_tz":-480,"elapsed":8,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"outputs":[],"source":["def make_model(\n","    src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1\n","):\n","    \"Helper: Construct a model from hyperparameters.\"\n","    c = copy.deepcopy\n","    attn = MultiHeadedAttention(h, d_model)\n","    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n","    position = PositionalEncoding(d_model, dropout)\n","    model = EncoderDecoder(\n","        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n","        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N),\n","        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n","        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n","        Generator(d_model, tgt_vocab),\n","    )\n","\n","    # This was important from their code.\n","    # Initialize parameters with Glorot / fan_avg.\n","    for p in model.parameters():\n","        if p.dim() > 1:\n","            nn.init.xavier_uniform_(p)\n","    return model"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5075,"status":"ok","timestamp":1723339318541,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"},"user_tz":-480},"id":"jpu8qRZlX75c","outputId":"7e7742d5-ad51-412d-9671-633fc8b1ec73"},"outputs":[{"output_type":"stream","name":"stdout","text":["Example Untrained Model Prediction: tensor([[0, 3, 7, 7, 7, 7, 7, 7, 5, 2]])\n","Example Untrained Model Prediction: tensor([[ 0,  8, 10, 10,  8,  1,  2,  8,  1, 10]])\n","Example Untrained Model Prediction: tensor([[0, 3, 8, 3, 8, 3, 8, 3, 8, 3]])\n","Example Untrained Model Prediction: tensor([[0, 8, 0, 6, 7, 0, 6, 7, 0, 6]])\n","Example Untrained Model Prediction: tensor([[0, 3, 3, 3, 3, 3, 3, 7, 3, 7]])\n","Example Untrained Model Prediction: tensor([[ 0, 10, 10, 10, 10, 10, 10, 10, 10, 10]])\n","Example Untrained Model Prediction: tensor([[0, 5, 8, 8, 8, 8, 8, 8, 8, 8]])\n","Example Untrained Model Prediction: tensor([[0, 7, 7, 7, 7, 7, 7, 8, 7, 7]])\n","Example Untrained Model Prediction: tensor([[0, 8, 5, 3, 4, 0, 0, 0, 0, 0]])\n","Example Untrained Model Prediction: tensor([[0, 3, 3, 4, 7, 1, 6, 7, 1, 6]])\n"]}],"source":["def inference_test():\n","    test_model = make_model(11, 11, 2)\n","    test_model.eval()\n","    src = torch.LongTensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n","    src_mask = torch.ones(1, 1, 10)\n","\n","    memory = test_model.encode(src, src_mask)\n","    ys = torch.zeros(1, 1).type_as(src)\n","\n","    for i in range(9):\n","        out = test_model.decode(\n","            memory, src_mask, ys, subsequent_mask(ys.size(1)).type_as(src.data)\n","        )\n","        prob = test_model.generator(out[:, -1])\n","        _, next_word = torch.max(prob, dim=1)\n","        next_word = next_word.data[0]\n","        ys = torch.cat(\n","            [ys, torch.empty(1, 1).type_as(src.data).fill_(next_word)], dim=1\n","        )\n","\n","    print(\"Example Untrained Model Prediction:\", ys)\n","\n","\n","def run_tests():\n","    for _ in range(10):\n","        inference_test()\n","\n","\n","show_example(run_tests)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"S_nyynCzYAaW","executionInfo":{"status":"ok","timestamp":1723339318542,"user_tz":-480,"elapsed":17,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"outputs":[],"source":["class Batch:\n","    \"\"\"Object for holding a batch of data with mask during training.\"\"\"\n","\n","    def __init__(self, src, tgt=None, pad=2):  # 2 = <blank>\n","        self.src = src\n","        self.src_mask = (src != pad).unsqueeze(-2)\n","        if tgt is not None:\n","            self.tgt = tgt[:, :-1]\n","            self.tgt_y = tgt[:, 1:]\n","            self.tgt_mask = self.make_std_mask(self.tgt, pad)\n","            self.ntokens = (self.tgt_y != pad).data.sum()\n","\n","    @staticmethod\n","    def make_std_mask(tgt, pad):\n","        \"Create a mask to hide padding and future words.\"\n","        tgt_mask = (tgt != pad).unsqueeze(-2)\n","        tgt_mask = tgt_mask & subsequent_mask(tgt.size(-1)).type_as(\n","            tgt_mask.data\n","        )\n","        return tgt_mask"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"2DaTDEU8YUtQ","executionInfo":{"status":"ok","timestamp":1723339318542,"user_tz":-480,"elapsed":16,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"outputs":[],"source":["# Note how a class is used to hold the values of important parameters.\n","class TrainState:\n","    \"\"\"Track number of steps, examples, and tokens processed\"\"\"\n","\n","    step: int = 0  # Steps in the current epoch\n","    accum_step: int = 0  # Number of gradient accumulation steps\n","    samples: int = 0  # total # of examples used\n","    tokens: int = 0  # total # of tokens processed"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"bXuWo7IlYYd4","executionInfo":{"status":"ok","timestamp":1723339318542,"user_tz":-480,"elapsed":16,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"outputs":[],"source":["def run_epoch(\n","    data_iter,\n","    model,\n","    loss_compute,\n","    optimizer,\n","    scheduler,\n","    mode=\"train\",\n","    accum_iter=1,\n","    train_state=TrainState(),\n","):\n","    \"\"\"Train a single epoch\"\"\"\n","    start = time.time()\n","    total_tokens = 0\n","    total_loss = 0\n","    tokens = 0\n","    n_accum = 0\n","    for i, batch in enumerate(data_iter):\n","        out = model.forward(\n","            batch.src, batch.tgt, batch.src_mask, batch.tgt_mask\n","        )\n","        loss, loss_node = loss_compute(out, batch.tgt_y, batch.ntokens)\n","        # loss_node = loss_node / accum_iter\n","        if mode == \"train\" or mode == \"train+log\":\n","            loss_node.backward()\n","            train_state.step += 1\n","            train_state.samples += batch.src.shape[0]\n","            train_state.tokens += batch.ntokens\n","            if i % accum_iter == 0:\n","                optimizer.step()\n","                optimizer.zero_grad(set_to_none=True)\n","                n_accum += 1\n","                train_state.accum_step += 1\n","            scheduler.step()\n","\n","        total_loss += loss\n","        total_tokens += batch.ntokens\n","        tokens += batch.ntokens\n","        if i % 40 == 1 and (mode == \"train\" or mode == \"train+log\"):\n","            lr = optimizer.param_groups[0][\"lr\"]\n","            elapsed = time.time() - start\n","            print(\n","                (\n","                    \"Epoch Step: %6d | Accumulation Step: %3d | Loss: %6.2f \"\n","                    + \"| Tokens / Sec: %7.1f | Learning Rate: %6.1e\"\n","                )\n","                % (i, n_accum, loss / batch.ntokens, tokens / elapsed, lr)\n","            )\n","            start = time.time()\n","            tokens = 0\n","        del loss\n","        del loss_node\n","    return total_loss / total_tokens, train_state"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"-sB1D2qtYcX3","executionInfo":{"status":"ok","timestamp":1723339318542,"user_tz":-480,"elapsed":15,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"outputs":[],"source":["def rate(step, model_size, factor, warmup):\n","    \"\"\"\n","    we have to default the step to 1 for LambdaLR function\n","    to avoid zero raising to negative power.\n","    \"\"\"\n","    if step == 0:\n","        step = 1\n","    return factor * (\n","        model_size ** (-0.5) * min(step ** (-0.5), step * warmup ** (-1.5))\n","    )"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":388,"output_embedded_package_id":"1TFxYSykX9IlCK2UCkPO2D9OwrN1Ep0Ma"},"executionInfo":{"elapsed":16072,"status":"ok","timestamp":1723339334600,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"},"user_tz":-480},"id":"dcjI-J6yYkC1","outputId":"13074500-81bf-4d51-98cb-eb6883725382"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["def example_learning_schedule():\n","    opts = [\n","        [512, 1, 4000],  # example 1\n","        [512, 1, 8000],  # example 2\n","        [256, 1, 4000],  # example 3\n","    ]\n","\n","    dummy_model = torch.nn.Linear(1, 1)\n","    learning_rates = []\n","\n","    # we have 3 examples in opts list.\n","    for idx, example in enumerate(opts):\n","        # run 20000 epoch for each example\n","        optimizer = torch.optim.Adam(\n","            dummy_model.parameters(), lr=1, betas=(0.9, 0.98), eps=1e-9\n","        )\n","        lr_scheduler = LambdaLR(\n","            optimizer=optimizer, lr_lambda=lambda step: rate(step, *example)\n","        )\n","        tmp = []\n","        # take 20K dummy training steps, save the learning rate at each step\n","        for step in range(20000):\n","            tmp.append(optimizer.param_groups[0][\"lr\"])\n","            optimizer.step()\n","            lr_scheduler.step()\n","        learning_rates.append(tmp)\n","\n","    learning_rates = torch.tensor(learning_rates)\n","\n","    # Enable altair to handle more than 5000 rows\n","    alt.data_transformers.disable_max_rows()\n","\n","    opts_data = pd.concat(\n","        [\n","            pd.DataFrame(\n","                {\n","                    \"Learning Rate\": learning_rates[warmup_idx, :],\n","                    \"model_size:warmup\": [\"512:4000\", \"512:8000\", \"256:4000\"][\n","                        warmup_idx\n","                    ],\n","                    \"step\": range(20000),\n","                }\n","            )\n","            for warmup_idx in [0, 1, 2]\n","        ]\n","    )\n","\n","    return (\n","        alt.Chart(opts_data)\n","        .mark_line()\n","        .properties(width=600)\n","        .encode(x=\"step\", y=\"Learning Rate\", color=\"model_size:warmup:N\")\n","        .interactive()\n","    )\n","\n","\n","example_learning_schedule()"]},{"cell_type":"markdown","metadata":{"id":"irCKZmk-Y4Ng"},"source":["# Regularization\n","\n","The original paper on label smoothing is cited Annotated Transformer listed in the README file for these notes."]},{"cell_type":"code","execution_count":31,"metadata":{"id":"t7iCMGGeWYJt","executionInfo":{"status":"ok","timestamp":1723339334601,"user_tz":-480,"elapsed":37,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"outputs":[],"source":["class LabelSmoothing(nn.Module):\n","    \"Implement label smoothing.\"\n","\n","    def __init__(self, size, padding_idx, smoothing=0.0):\n","        super(LabelSmoothing, self).__init__()\n","        self.criterion = nn.KLDivLoss(reduction=\"sum\")\n","        self.padding_idx = padding_idx\n","        self.confidence = 1.0 - smoothing\n","        self.smoothing = smoothing\n","        self.size = size\n","        self.true_dist = None\n","\n","    def forward(self, x, target):\n","        assert x.size(1) == self.size\n","        true_dist = x.data.clone()\n","        true_dist.fill_(self.smoothing / (self.size - 2))\n","        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n","        true_dist[:, self.padding_idx] = 0\n","        mask = torch.nonzero(target.data == self.padding_idx)\n","        if mask.dim() > 0:\n","            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n","        self.true_dist = true_dist\n","        return self.criterion(x, true_dist.clone().detach())"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":247},"executionInfo":{"elapsed":36,"status":"ok","timestamp":1723339334601,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"},"user_tz":-480},"id":"UCx4cibJYf0q","outputId":"092065ab-f8cd-4333-c5ce-3c9ee8e77097"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","<div id=\"altair-viz-92c51861b3c446cfa869f188317de99b\"></div>\n","<script type=\"text/javascript\">\n","  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n","  (function(spec, embedOpt){\n","    let outputDiv = document.currentScript.previousElementSibling;\n","    if (outputDiv.id !== \"altair-viz-92c51861b3c446cfa869f188317de99b\") {\n","      outputDiv = document.getElementById(\"altair-viz-92c51861b3c446cfa869f188317de99b\");\n","    }\n","    const paths = {\n","      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n","      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n","      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n","      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n","    };\n","\n","    function maybeLoadScript(lib, version) {\n","      var key = `${lib.replace(\"-\", \"\")}_version`;\n","      return (VEGA_DEBUG[key] == version) ?\n","        Promise.resolve(paths[lib]) :\n","        new Promise(function(resolve, reject) {\n","          var s = document.createElement('script');\n","          document.getElementsByTagName(\"head\")[0].appendChild(s);\n","          s.async = true;\n","          s.onload = () => {\n","            VEGA_DEBUG[key] = version;\n","            return resolve(paths[lib]);\n","          };\n","          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n","          s.src = paths[lib];\n","        });\n","    }\n","\n","    function showError(err) {\n","      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n","      throw err;\n","    }\n","\n","    function displayChart(vegaEmbed) {\n","      vegaEmbed(outputDiv, spec, embedOpt)\n","        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n","    }\n","\n","    if(typeof define === \"function\" && define.amd) {\n","      requirejs.config({paths});\n","      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n","    } else {\n","      maybeLoadScript(\"vega\", \"5\")\n","        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n","        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n","        .catch(showError)\n","        .then(() => displayChart(vegaEmbed));\n","    }\n","  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-657da60f13fd21ce0024d47b52e08641\"}, \"mark\": {\"type\": \"rect\", \"color\": \"Blue\", \"opacity\": 1}, \"encoding\": {\"color\": {\"field\": \"target distribution\", \"scale\": {\"scheme\": \"viridis\"}, \"type\": \"quantitative\"}, \"x\": {\"field\": \"columns\", \"title\": null, \"type\": \"ordinal\"}, \"y\": {\"field\": \"rows\", \"title\": null, \"type\": \"ordinal\"}}, \"height\": 200, \"selection\": {\"selector004\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"width\": 200, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-657da60f13fd21ce0024d47b52e08641\": [{\"target distribution\": 0.0, \"columns\": 0, \"rows\": 0}, {\"target distribution\": 0.0, \"columns\": 0, \"rows\": 1}, {\"target distribution\": 0.0, \"columns\": 0, \"rows\": 2}, {\"target distribution\": 0.0, \"columns\": 0, \"rows\": 3}, {\"target distribution\": 0.0, \"columns\": 0, \"rows\": 4}, {\"target distribution\": 0.13333334028720856, \"columns\": 1, \"rows\": 0}, {\"target distribution\": 0.6000000238418579, \"columns\": 1, \"rows\": 1}, {\"target distribution\": 0.0, \"columns\": 1, \"rows\": 2}, {\"target distribution\": 0.13333334028720856, \"columns\": 1, \"rows\": 3}, {\"target distribution\": 0.13333334028720856, \"columns\": 1, \"rows\": 4}, {\"target distribution\": 0.6000000238418579, \"columns\": 2, \"rows\": 0}, {\"target distribution\": 0.13333334028720856, \"columns\": 2, \"rows\": 1}, {\"target distribution\": 0.0, \"columns\": 2, \"rows\": 2}, {\"target distribution\": 0.13333334028720856, \"columns\": 2, \"rows\": 3}, {\"target distribution\": 0.13333334028720856, \"columns\": 2, \"rows\": 4}, {\"target distribution\": 0.13333334028720856, \"columns\": 3, \"rows\": 0}, {\"target distribution\": 0.13333334028720856, \"columns\": 3, \"rows\": 1}, {\"target distribution\": 0.0, \"columns\": 3, \"rows\": 2}, {\"target distribution\": 0.6000000238418579, \"columns\": 3, \"rows\": 3}, {\"target distribution\": 0.6000000238418579, \"columns\": 3, \"rows\": 4}, {\"target distribution\": 0.13333334028720856, \"columns\": 4, \"rows\": 0}, {\"target distribution\": 0.13333334028720856, \"columns\": 4, \"rows\": 1}, {\"target distribution\": 0.0, \"columns\": 4, \"rows\": 2}, {\"target distribution\": 0.13333334028720856, \"columns\": 4, \"rows\": 3}, {\"target distribution\": 0.13333334028720856, \"columns\": 4, \"rows\": 4}]}}, {\"mode\": \"vega-lite\"});\n","</script>"],"text/plain":["alt.Chart(...)"]},"metadata":{},"execution_count":32}],"source":["# Example of label smoothing.\n","\n","def example_label_smoothing():\n","    crit = LabelSmoothing(5, 0, 0.4)\n","    predict = torch.FloatTensor(\n","        [\n","            [0, 0.2, 0.7, 0.1, 0],\n","            [0, 0.2, 0.7, 0.1, 0],\n","            [0, 0.2, 0.7, 0.1, 0],\n","            [0, 0.2, 0.7, 0.1, 0],\n","            [0, 0.2, 0.7, 0.1, 0],\n","        ]\n","    )\n","    crit(x=predict.log(), target=torch.LongTensor([2, 1, 0, 3, 3]))\n","    LS_data = pd.concat(\n","        [\n","            pd.DataFrame(\n","                {\n","                    \"target distribution\": crit.true_dist[x, y].flatten(),\n","                    \"columns\": y,\n","                    \"rows\": x,\n","                }\n","            )\n","            for y in range(5)\n","            for x in range(5)\n","        ]\n","    )\n","\n","    return (\n","        alt.Chart(LS_data)\n","        .mark_rect(color=\"Blue\", opacity=1)\n","        .properties(height=200, width=200)\n","        .encode(\n","            alt.X(\"columns:O\", title=None),\n","            alt.Y(\"rows:O\", title=None),\n","            alt.Color(\n","                \"target distribution:Q\", scale=alt.Scale(scheme=\"viridis\")\n","            ),\n","        )\n","        .interactive()\n","    )\n","\n","show_example(example_label_smoothing)\n"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1723339334601,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"},"user_tz":-480},"id":"OEi_FZtrYthM","outputId":"488a72ba-8e4f-479c-8e44-84f54f1f29c7"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","<div id=\"altair-viz-169b7dacc28b4663aad06ce9327f034c\"></div>\n","<script type=\"text/javascript\">\n","  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n","  (function(spec, embedOpt){\n","    let outputDiv = document.currentScript.previousElementSibling;\n","    if (outputDiv.id !== \"altair-viz-169b7dacc28b4663aad06ce9327f034c\") {\n","      outputDiv = document.getElementById(\"altair-viz-169b7dacc28b4663aad06ce9327f034c\");\n","    }\n","    const paths = {\n","      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n","      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n","      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n","      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n","    };\n","\n","    function maybeLoadScript(lib, version) {\n","      var key = `${lib.replace(\"-\", \"\")}_version`;\n","      return (VEGA_DEBUG[key] == version) ?\n","        Promise.resolve(paths[lib]) :\n","        new Promise(function(resolve, reject) {\n","          var s = document.createElement('script');\n","          document.getElementsByTagName(\"head\")[0].appendChild(s);\n","          s.async = true;\n","          s.onload = () => {\n","            VEGA_DEBUG[key] = version;\n","            return resolve(paths[lib]);\n","          };\n","          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n","          s.src = paths[lib];\n","        });\n","    }\n","\n","    function showError(err) {\n","      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n","      throw err;\n","    }\n","\n","    function displayChart(vegaEmbed) {\n","      vegaEmbed(outputDiv, spec, embedOpt)\n","        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n","    }\n","\n","    if(typeof define === \"function\" && define.amd) {\n","      requirejs.config({paths});\n","      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n","    } else {\n","      maybeLoadScript(\"vega\", \"5\")\n","        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n","        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n","        .catch(showError)\n","        .then(() => displayChart(vegaEmbed));\n","    }\n","  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-78340999df5105e08f151e63643248fc\"}, \"mark\": \"line\", \"encoding\": {\"x\": {\"field\": \"Steps\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Loss\", \"type\": \"quantitative\"}}, \"selection\": {\"selector005\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"width\": 350, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-78340999df5105e08f151e63643248fc\": [{\"Loss\": 0.9513500928878784, \"Steps\": 0.0}, {\"Loss\": 0.5506610870361328, \"Steps\": 1.0}, {\"Loss\": 0.36806410551071167, \"Steps\": 2.0}, {\"Loss\": 0.26330095529556274, \"Steps\": 3.0}, {\"Loss\": 0.19600319862365723, \"Steps\": 4.0}, {\"Loss\": 0.14969676733016968, \"Steps\": 5.0}, {\"Loss\": 0.11632175743579865, \"Steps\": 6.0}, {\"Loss\": 0.09145362675189972, \"Steps\": 7.0}, {\"Loss\": 0.07246027886867523, \"Steps\": 8.0}, {\"Loss\": 0.05767851322889328, \"Steps\": 9.0}, {\"Loss\": 0.04600733518600464, \"Steps\": 10.0}, {\"Loss\": 0.036689966917037964, \"Steps\": 11.0}, {\"Loss\": 0.0291900634765625, \"Steps\": 12.0}, {\"Loss\": 0.02311749756336212, \"Steps\": 13.0}, {\"Loss\": 0.018182365223765373, \"Steps\": 14.0}, {\"Loss\": 0.01416487991809845, \"Steps\": 15.0}, {\"Loss\": 0.010896005667746067, \"Steps\": 16.0}, {\"Loss\": 0.008243615739047527, \"Steps\": 17.0}, {\"Loss\": 0.006103138439357281, \"Steps\": 18.0}, {\"Loss\": 0.004390960559248924, \"Steps\": 19.0}, {\"Loss\": 0.003039402887225151, \"Steps\": 20.0}, {\"Loss\": 0.0019933986477553844, \"Steps\": 21.0}, {\"Loss\": 0.0012075277045369148, \"Steps\": 22.0}, {\"Loss\": 0.0006441792938858271, \"Steps\": 23.0}, {\"Loss\": 0.00027202535420656204, \"Steps\": 24.0}, {\"Loss\": 6.469688378274441e-05, \"Steps\": 25.0}, {\"Loss\": 0.0, \"Steps\": 26.0}, {\"Loss\": 5.8931997045874596e-05, \"Steps\": 27.0}, {\"Loss\": 0.00022542336955666542, \"Steps\": 28.0}, {\"Loss\": 0.00048566749319434166, \"Steps\": 29.0}, {\"Loss\": 0.0008278326131403446, \"Steps\": 30.0}, {\"Loss\": 0.0012415172532200813, \"Steps\": 31.0}, {\"Loss\": 0.0017178812995553017, \"Steps\": 32.0}, {\"Loss\": 0.002249208278954029, \"Steps\": 33.0}, {\"Loss\": 0.002828662283718586, \"Steps\": 34.0}, {\"Loss\": 0.003450361080467701, \"Steps\": 35.0}, {\"Loss\": 0.004109090194106102, \"Steps\": 36.0}, {\"Loss\": 0.004800276830792427, \"Steps\": 37.0}, {\"Loss\": 0.0055199358612298965, \"Steps\": 38.0}, {\"Loss\": 0.006264356896281242, \"Steps\": 39.0}, {\"Loss\": 0.00703054666519165, \"Steps\": 40.0}, {\"Loss\": 0.007815608754754066, \"Steps\": 41.0}, {\"Loss\": 0.008617045357823372, \"Steps\": 42.0}, {\"Loss\": 0.009432701393961906, \"Steps\": 43.0}, {\"Loss\": 0.010260546579957008, \"Steps\": 44.0}, {\"Loss\": 0.011098792776465416, \"Steps\": 45.0}, {\"Loss\": 0.011945942416787148, \"Steps\": 46.0}, {\"Loss\": 0.012800488620996475, \"Steps\": 47.0}, {\"Loss\": 0.013661196455359459, \"Steps\": 48.0}, {\"Loss\": 0.014526985585689545, \"Steps\": 49.0}, {\"Loss\": 0.015396779403090477, \"Steps\": 50.0}, {\"Loss\": 0.016269627958536148, \"Steps\": 51.0}, {\"Loss\": 0.017144696786999702, \"Steps\": 52.0}, {\"Loss\": 0.018021374940872192, \"Steps\": 53.0}, {\"Loss\": 0.01889890432357788, \"Steps\": 54.0}, {\"Loss\": 0.019776713103055954, \"Steps\": 55.0}, {\"Loss\": 0.020654210820794106, \"Steps\": 56.0}, {\"Loss\": 0.021530907601118088, \"Steps\": 57.0}, {\"Loss\": 0.022406460717320442, \"Steps\": 58.0}, {\"Loss\": 0.023280372843146324, \"Steps\": 59.0}, {\"Loss\": 0.024152379482984543, \"Steps\": 60.0}, {\"Loss\": 0.0250221099704504, \"Steps\": 61.0}, {\"Loss\": 0.025889279320836067, \"Steps\": 62.0}, {\"Loss\": 0.026753658428788185, \"Steps\": 63.0}, {\"Loss\": 0.027614915743470192, \"Steps\": 64.0}, {\"Loss\": 0.02847300097346306, \"Steps\": 65.0}, {\"Loss\": 0.029327666386961937, \"Steps\": 66.0}, {\"Loss\": 0.03017870895564556, \"Steps\": 67.0}, {\"Loss\": 0.03102605789899826, \"Steps\": 68.0}, {\"Loss\": 0.03186953812837601, \"Steps\": 69.0}, {\"Loss\": 0.032708972692489624, \"Steps\": 70.0}, {\"Loss\": 0.03354441374540329, \"Steps\": 71.0}, {\"Loss\": 0.0343756377696991, \"Steps\": 72.0}, {\"Loss\": 0.03520261496305466, \"Steps\": 73.0}, {\"Loss\": 0.036025337874889374, \"Steps\": 74.0}, {\"Loss\": 0.03684357553720474, \"Steps\": 75.0}, {\"Loss\": 0.03765755146741867, \"Steps\": 76.0}, {\"Loss\": 0.03846696764230728, \"Steps\": 77.0}, {\"Loss\": 0.039271969348192215, \"Steps\": 78.0}, {\"Loss\": 0.040072374045848846, \"Steps\": 79.0}, {\"Loss\": 0.04086829721927643, \"Steps\": 80.0}, {\"Loss\": 0.04165971279144287, \"Steps\": 81.0}, {\"Loss\": 0.04244651645421982, \"Steps\": 82.0}, {\"Loss\": 0.043228790163993835, \"Steps\": 83.0}, {\"Loss\": 0.04400648549199104, \"Steps\": 84.0}, {\"Loss\": 0.04477958753705025, \"Steps\": 85.0}, {\"Loss\": 0.04554816707968712, \"Steps\": 86.0}, {\"Loss\": 0.04631214961409569, \"Steps\": 87.0}, {\"Loss\": 0.04707161709666252, \"Steps\": 88.0}, {\"Loss\": 0.047826580703258514, \"Steps\": 89.0}, {\"Loss\": 0.048577018082141876, \"Steps\": 90.0}, {\"Loss\": 0.049322955310344696, \"Steps\": 91.0}, {\"Loss\": 0.05006442964076996, \"Steps\": 92.0}, {\"Loss\": 0.050801437348127365, \"Steps\": 93.0}, {\"Loss\": 0.051534052938222885, \"Steps\": 94.0}, {\"Loss\": 0.05226223170757294, \"Steps\": 95.0}, {\"Loss\": 0.052986059337854385, \"Steps\": 96.0}, {\"Loss\": 0.05370553210377693, \"Steps\": 97.0}, {\"Loss\": 0.05442074313759804, \"Steps\": 98.0}]}}, {\"mode\": \"vega-lite\"});\n","</script>"],"text/plain":["alt.Chart(...)"]},"metadata":{},"execution_count":33}],"source":["\n","\n","def loss(x, crit):\n","    d = x + 3 * 1\n","    predict = torch.FloatTensor([[0, x / d, 1 / d, 1 / d, 1 / d]])\n","    return crit(predict.log(), torch.LongTensor([1])).data\n","\n","\n","def penalization_visualization():\n","    crit = LabelSmoothing(5, 0, 0.1)\n","    loss_data = pd.DataFrame(\n","        {\n","            \"Loss\": [loss(x, crit) for x in range(1, 100)],\n","            \"Steps\": list(range(99)),\n","        }\n","    ).astype(\"float\")\n","\n","    return (\n","        alt.Chart(loss_data)\n","        .mark_line()\n","        .properties(width=350)\n","        .encode(\n","            x=\"Steps\",\n","            y=\"Loss\",\n","        )\n","        .interactive()\n","    )\n","\n","\n","show_example(penalization_visualization)"]},{"cell_type":"markdown","metadata":{"id":"bSk0_0uI5ucH"},"source":["First example:  The copy-task or identity function."]},{"cell_type":"code","execution_count":34,"metadata":{"id":"MuTjPpOC5vmv","executionInfo":{"status":"ok","timestamp":1723339334602,"user_tz":-480,"elapsed":34,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"outputs":[],"source":["def data_gen(V, batch_size, nbatches):\n","    \"Generate random data for a src-tgt copy task.\"\n","    for i in range(nbatches):\n","        data = torch.randint(1, V, size=(batch_size, 10))\n","        data[:, 0] = 1\n","        src = data.requires_grad_(False).clone().detach()\n","        tgt = data.requires_grad_(False).clone().detach()\n","        yield Batch(src, tgt, 0)"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"rjo4LgXb59Ap","executionInfo":{"status":"ok","timestamp":1723339334602,"user_tz":-480,"elapsed":34,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"outputs":[],"source":["class SimpleLossCompute:\n","    \"A simple loss compute and train function.\"\n","\n","    def __init__(self, generator, criterion):\n","        self.generator = generator\n","        self.criterion = criterion\n","\n","    def __call__(self, x, y, norm):\n","        x = self.generator(x)\n","        sloss = (\n","            self.criterion(\n","                x.contiguous().view(-1, x.size(-1)), y.contiguous().view(-1)\n","            )\n","            / norm\n","        )\n","        return sloss.data * norm, sloss"]},{"cell_type":"markdown","source":["Greedy decoding is used the predict the translation.   Basically the model choses the translation with the highest probability."],"metadata":{"id":"_2pSL8iY_khZ"}},{"cell_type":"code","execution_count":36,"metadata":{"id":"lh-CBICH6EAZ","executionInfo":{"status":"ok","timestamp":1723339334602,"user_tz":-480,"elapsed":34,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"outputs":[],"source":["def greedy_decode(model, src, src_mask, max_len, start_symbol):\n","    memory = model.encode(src, src_mask)\n","    ys = torch.zeros(1, 1).fill_(start_symbol).type_as(src.data)\n","    for i in range(max_len - 1):\n","        out = model.decode(\n","            memory, src_mask, ys, subsequent_mask(ys.size(1)).type_as(src.data)\n","        )\n","        prob = model.generator(out[:, -1])\n","        _, next_word = torch.max(prob, dim=1)\n","        next_word = next_word.data[0]\n","        ys = torch.cat(\n","            [ys, torch.zeros(1, 1).type_as(src.data).fill_(next_word)], dim=1\n","        )\n","    return ys"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vJ17fgaD6Hqa","executionInfo":{"status":"ok","timestamp":1723339842569,"user_tz":-480,"elapsed":508001,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}},"outputId":"f43bd8cc-e8e5-42c0-bb74-aab68a60285a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch Step:      1 | Accumulation Step:   2 | Loss:   3.66 | Tokens / Sec:   444.1 | Learning Rate: 5.5e-06\n","Epoch Step:      1 | Accumulation Step:   2 | Loss:   2.17 | Tokens / Sec:   670.3 | Learning Rate: 6.1e-05\n","Epoch Step:      1 | Accumulation Step:   2 | Loss:   1.81 | Tokens / Sec:   680.7 | Learning Rate: 1.2e-04\n","Epoch Step:      1 | Accumulation Step:   2 | Loss:   1.54 | Tokens / Sec:   668.7 | Learning Rate: 1.7e-04\n","Epoch Step:      1 | Accumulation Step:   2 | Loss:   1.19 | Tokens / Sec:   678.0 | Learning Rate: 2.3e-04\n","Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.73 | Tokens / Sec:   647.4 | Learning Rate: 2.8e-04\n","Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.36 | Tokens / Sec:   516.1 | Learning Rate: 3.4e-04\n","Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.28 | Tokens / Sec:   452.2 | Learning Rate: 3.9e-04\n","Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.18 | Tokens / Sec:   503.6 | Learning Rate: 4.5e-04\n","Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.13 | Tokens / Sec:   615.8 | Learning Rate: 5.0e-04\n","Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.12 | Tokens / Sec:   667.6 | Learning Rate: 5.6e-04\n","Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.10 | Tokens / Sec:   673.9 | Learning Rate: 6.1e-04\n","Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.07 | Tokens / Sec:   668.8 | Learning Rate: 6.7e-04\n","Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.13 | Tokens / Sec:   670.4 | Learning Rate: 7.2e-04\n","Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.12 | Tokens / Sec:   678.7 | Learning Rate: 7.8e-04\n","Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.11 | Tokens / Sec:   663.0 | Learning Rate: 8.3e-04\n","Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.22 | Tokens / Sec:   663.6 | Learning Rate: 8.9e-04\n","Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.15 | Tokens / Sec:   658.9 | Learning Rate: 9.4e-04\n","Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.09 | Tokens / Sec:   671.7 | Learning Rate: 1.0e-03\n","Epoch Step:      1 | Accumulation Step:   2 | Loss:   0.20 | Tokens / Sec:   471.4 | Learning Rate: 1.1e-03\n","tensor([[0, 1, 2, 3, 4, 1, 2, 3, 4, 5]])\n"]}],"source":["# Train the simple copy task.  The model generates the input tensor (src).\n","\n","\n","def example_simple_model():\n","    V = 11\n","    criterion = LabelSmoothing(size=V, padding_idx=0, smoothing=0.0)\n","    model = make_model(V, V, N=2)\n","\n","    optimizer = torch.optim.Adam(\n","        model.parameters(), lr=0.5, betas=(0.9, 0.98), eps=1e-9\n","    )\n","    lr_scheduler = LambdaLR(\n","        optimizer=optimizer,\n","        lr_lambda=lambda step: rate(\n","            step, model_size=model.src_embed[0].d_model, factor=1.0, warmup=400\n","        ),\n","    )\n","\n","    batch_size = 80\n","    for epoch in range(20):\n","        model.train()\n","        run_epoch(\n","            data_gen(V, batch_size, 20),\n","            model,\n","            SimpleLossCompute(model.generator, criterion),\n","            optimizer,\n","            lr_scheduler,\n","            mode=\"train\",\n","        )\n","        model.eval()\n","        run_epoch(\n","            data_gen(V, batch_size, 5),\n","            model,\n","            SimpleLossCompute(model.generator, criterion),\n","            DummyOptimizer(),\n","            DummyScheduler(),\n","            mode=\"eval\",\n","        )[0]\n","\n","    model.eval()\n","    src = torch.LongTensor([[0, 1, 2, 3, 4, 1, 2, 3, 4, 5]])\n","    max_len = src.shape[1]\n","    src_mask = torch.ones(1, 1, max_len)\n","    print(greedy_decode(model, src, src_mask, max_len=max_len, start_symbol=0))\n","\n","\n","execute_example(example_simple_model)"]},{"cell_type":"markdown","source":["# Part 3:  A Real World Example"],"metadata":{"id":"4XVRz1goBrQb"}},{"cell_type":"markdown","source":["Since the Multi30K dataset is offline, I am going to implement the dataset by hand.   I will use this the German/English dataset from the European Parliament Proceedings Parallel Corpus 1996-2011 found here\n","https://www.statmt.org/europarl/.   I am go to trying using 100000, 4000, 4000 sentences for the training, testing, and validation sets.  The datasets should be list of tuples of parallel German/English sentences.  For example:\n","\n","test = [(german_sent_1, english_sent_1), ...\n","(german_sent_N, englishsent_N)]\n","\n","sample_list = [('Wiederaufnahme der Sitzungsperiode\\n', 'Resumption of the session\\n'), ('Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.\\n', 'I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.\\n'), ('Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.\\n', \"Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\\n\")]"],"metadata":{"id":"BsDFpGiBNIxd"}},{"cell_type":"code","source":["\"\"\" Move to the directory containing the language datesets.\"\"\"\n","import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","os.chdir(\"/content/drive/MyDrive/Colab Notebooks/transformer/datasets/de-en\")\n","# os.chdir(\"/content/datasets\")\n","os.getcwd()\n","os.listdir()\n","print(os.getcwd())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2VKIjFrE-Amf","executionInfo":{"status":"ok","timestamp":1723340145536,"user_tz":-480,"elapsed":111989,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}},"outputId":"607eab8a-3216-46cf-d03f-4610a8864564"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks/transformer/datasets/de-en\n"]}]},{"cell_type":"code","source":["\"\"\"Some code to open two large file containing parallel German/English sentences\n","and construct the dataset needed for training the transformer.\"\"\"\n","\n","\"\"\" The language files are stored in my Google Drive.   The drive needs to be mounted at the\n","beginning of the session from the CoLab file menu.   The code in the previous cell\n","will set the cwd to the appropriate folder\"\"\"\n","\n","\"\"\"\n","******************************************\n","To switch to Spanish I need the files for Spanish/English text pairs referenced here\n","and the files stored in the cwd.\n","******************************************\n","\n","\"\"\"\n","\n","my_file_en = \"europarl-v7.de-en.en\"\n","my_file_de = \"europarl-v7.de-en.de\"\n","\n","# my_file_en = \"\"\n","# my_file_es = \"\"\n","\n","# May need to adjust these parameters for new translation tasks.\n","size_train = 2\n","size_val = 1\n","size_test = 1\n","\n","train = []\n","val = []\n","test = []\n","\n","de_list = []\n","en_list = []\n","\n","count = 0;\n","with open(my_file_de, encoding=\"utf8\") as fp:\n","  for line in fp:\n","    de_list.append(line)\n","    if count >= (size_train + size_val + size_test - 1):\n","      break\n","    count += 1\n","\n","count = 0;\n","with open(my_file_en, encoding=\"utf8\") as fp:\n","  for line in fp:\n","    en_list.append(line)\n","    if count > (size_train + size_val + size_test - 1):\n","      break\n","    count += 1\n","\n","dataset = list(zip(de_list, en_list))\n","train = dataset[:size_train]\n","val = dataset[size_train:size_train+size_val]\n","test = dataset[size_train+size_val:size_train+size_val+size_test]\n","\n","print(len(train), len(val), len(test))\n","print(train)\n","\n","\n"],"metadata":{"id":"KI3GHyaY0qrT","executionInfo":{"status":"ok","timestamp":1723345113559,"user_tz":-480,"elapsed":492,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"166608a8-7380-4e92-fdeb-038aa9760545"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["2 1 1\n","[('Wiederaufnahme der Sitzungsperiode\\n', 'Resumption of the session\\n'), ('Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.\\n', 'I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.\\n')]\n"]}]},{"cell_type":"code","source":["# Load spacy tokenizer models, download them if they haven't been\n","# downloaded already\n","\n","\n","def load_tokenizers():\n","\n","    try:\n","        spacy_de = spacy.load(\"de_core_news_sm\")\n","    except IOError:\n","        os.system(\"python -m spacy download de_core_news_sm\")\n","        spacy_de = spacy.load(\"de_core_news_sm\")\n","\n","    try:\n","        spacy_en = spacy.load(\"en_core_web_sm\")\n","    except IOError:\n","        os.system(\"python -m spacy download en_core_web_sm\")\n","        spacy_en = spacy.load(\"en_core_web_sm\")\n","\n","    return spacy_de, spacy_en"],"metadata":{"id":"LYJCz4cWBxGU","executionInfo":{"status":"ok","timestamp":1723340189809,"user_tz":-480,"elapsed":405,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["def tokenize(text, tokenizer):\n","    return [tok.text for tok in tokenizer.tokenizer(text)]\n","\n","\n","def yield_tokens(data_iter, tokenizer, index):\n","    for from_to_tuple in data_iter:\n","        yield tokenizer(from_to_tuple[index])"],"metadata":{"id":"8QhbfkC2pfrn","executionInfo":{"status":"ok","timestamp":1723340193085,"user_tz":-480,"elapsed":438,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["\n","def build_vocabulary(spacy_de, spacy_en, train, val, test):\n","    def tokenize_de(text):\n","        return tokenize(text, spacy_de)\n","\n","    def tokenize_en(text):\n","        return tokenize(text, spacy_en)\n","\n","    print(\"Building German Vocabulary ...\")\n","    # train, val, test = datasets.Multi30k(language_pair=(\"de\", \"en\"))\n","    # train, val, test = datasets.IWSLT2017(language_pair=(\"de\", \"en\"))\n","    vocab_src = build_vocab_from_iterator(\n","        yield_tokens(train + val + test, tokenize_de, index=0),\n","        min_freq=2,\n","        specials=[\"<s>\", \"</s>\", \"<blank>\", \"<unk>\"],\n","    )\n","\n","    print(\"Building English Vocabulary ...\")\n","    # train, val, test = datasets.Multi30k(language_pair=(\"de\", \"en\"))\n","    # train, val, test = datasets.IWSLT2017(language_pair=(\"de\", \"en\"))\n","    vocab_tgt = build_vocab_from_iterator(\n","        yield_tokens(train + val + test, tokenize_en, index=1),\n","        min_freq=2,\n","        specials=[\"<s>\", \"</s>\", \"<blank>\", \"<unk>\"],\n","    )\n","\n","    vocab_src.set_default_index(vocab_src[\"<unk>\"])\n","    vocab_tgt.set_default_index(vocab_tgt[\"<unk>\"])\n","\n","    return vocab_src, vocab_tgt\n","\n","\n","def load_vocab(spacy_de, spacy_en):\n","    if not exists(\"vocab.pt\"):\n","        vocab_src, vocab_tgt = build_vocabulary(spacy_de, spacy_en, train, val, test)\n","        torch.save((vocab_src, vocab_tgt), \"vocab.pt\")\n","    else:\n","        vocab_src, vocab_tgt = torch.load(\"vocab.pt\")\n","    print(\"Finished.\\nVocabulary sizes:\")\n","    print(len(vocab_src))\n","    print(len(vocab_tgt))\n","    return vocab_src, vocab_tgt\n","\n","\n","if is_interactive_notebook():\n","    # global variables used later in the script\n","    spacy_de, spacy_en = show_example(load_tokenizers)\n","    vocab_src, vocab_tgt = show_example(load_vocab, args=[spacy_de, spacy_en])"],"metadata":{"id":"0a4Gw4eoB5Zh","executionInfo":{"status":"ok","timestamp":1723340197591,"user_tz":-480,"elapsed":2816,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b84794b2-96e0-4352-addc-f291be675e48"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Finished.\n","Vocabulary sizes:\n","11\n","20\n"]}]},{"cell_type":"markdown","source":["Perhaps this site could be helpful:\n","\n","See https://github.com/PetrochukM/PyTorch-NLP/blob/master/torchnlp/datasets/multi30k.py\n","\n","# !pip install pytorch-nlp\n","\n","These folks have written about the same problem:\n","\n","https://discuss.pytorch.org/t/build-vocab-from-iterator-does-not-work-in-notebook/153575/4\n","\n","Other possible source of answers:\n","https://github.com/pytorch/data"],"metadata":{"id":"CEHTey_7V-Cd"}},{"cell_type":"code","source":["def collate_batch(\n","    batch,\n","    src_pipeline,\n","    tgt_pipeline,\n","    src_vocab,\n","    tgt_vocab,\n","    device,\n","    max_padding=128,\n","    pad_id=2,\n","):\n","    bs_id = torch.tensor([0], device=device)  # <s> token id\n","    eos_id = torch.tensor([1], device=device)  # </s> token id\n","    src_list, tgt_list = [], []\n","    for (_src, _tgt) in batch:\n","        processed_src = torch.cat(\n","            [\n","                bs_id,\n","                torch.tensor(\n","                    src_vocab(src_pipeline(_src)),\n","                    dtype=torch.int64,\n","                    device=device,\n","                ),\n","                eos_id,\n","            ],\n","            0,\n","        )\n","        processed_tgt = torch.cat(\n","            [\n","                bs_id,\n","                torch.tensor(\n","                    tgt_vocab(tgt_pipeline(_tgt)),\n","                    dtype=torch.int64,\n","                    device=device,\n","                ),\n","                eos_id,\n","            ],\n","            0,\n","        )\n","        src_list.append(\n","            # warning - overwrites values for negative values of padding - len\n","            pad(\n","                processed_src,\n","                (\n","                    0,\n","                    max_padding - len(processed_src),\n","                ),\n","                value=pad_id,\n","            )\n","        )\n","        tgt_list.append(\n","            pad(\n","                processed_tgt,\n","                (0, max_padding - len(processed_tgt)),\n","                value=pad_id,\n","            )\n","        )\n","\n","    src = torch.stack(src_list)\n","    tgt = torch.stack(tgt_list)\n","    return (src, tgt)"],"metadata":{"id":"Okp1_0XoCHGx","executionInfo":{"status":"ok","timestamp":1723340202107,"user_tz":-480,"elapsed":496,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":["Need to (1) add parameters to create_dataloaders for train, val, and test and remove (2)  Remove call to datasets.Multi30K in the code below."],"metadata":{"id":"nAG0iK9wH23Z"}},{"cell_type":"code","source":["def create_dataloaders(\n","    device,\n","    vocab_src,\n","    vocab_tgt,\n","    spacy_de,\n","    spacy_en,\n","    batch_size=12000,\n","    max_padding=128,\n","    is_distributed=True,\n","):\n","    # def create_dataloaders(batch_size=12000):\n","    def tokenize_de(text):\n","        return tokenize(text, spacy_de)\n","\n","    def tokenize_en(text):\n","        return tokenize(text, spacy_en)\n","\n","    def collate_fn(batch):\n","        return collate_batch(\n","            batch,\n","            tokenize_de,\n","            tokenize_en,\n","            vocab_src,\n","            vocab_tgt,\n","            device,\n","            max_padding=max_padding,\n","            pad_id=vocab_src.get_stoi()[\"<blank>\"],\n","        )\n","    ##########################################################\n","    #  Here is the call to datasets that is causing the fail.\n","    ##########################################################\n","\n","    # Old code\n","    # train_iter, valid_iter, test_iter = datasets.Multi30k(\n","    #    language_pair=(\"de\", \"en\")\n","    #)\n","\n","    # Simple solution\n","    train_iter, valid_iter, test_iter = train, val, test\n","\n","    train_iter_map = to_map_style_dataset(\n","        train_iter\n","    )  # DistributedSampler needs a dataset len()\n","    train_sampler = (\n","        DistributedSampler(train_iter_map) if is_distributed else None\n","    )\n","    valid_iter_map = to_map_style_dataset(valid_iter)\n","    valid_sampler = (\n","        DistributedSampler(valid_iter_map) if is_distributed else None\n","    )\n","\n","    train_dataloader = DataLoader(\n","        train_iter_map,\n","        batch_size=batch_size,\n","        shuffle=(train_sampler is None),\n","        sampler=train_sampler,\n","        collate_fn=collate_fn,\n","    )\n","    valid_dataloader = DataLoader(\n","        valid_iter_map,\n","        batch_size=batch_size,\n","        shuffle=(valid_sampler is None),\n","        sampler=valid_sampler,\n","        collate_fn=collate_fn,\n","    )\n","    return train_dataloader, valid_dataloader"],"metadata":{"id":"6_U6_HEYCLQq","executionInfo":{"status":"ok","timestamp":1723340205102,"user_tz":-480,"elapsed":5,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["def train_worker(\n","    gpu,\n","    ngpus_per_node,\n","    vocab_src,\n","    vocab_tgt,\n","    spacy_de,\n","    spacy_en,\n","    config,\n","    is_distributed=False,\n","):\n","    print(f\"Train worker process using GPU: {gpu} for training\", flush=True)\n","    torch.cuda.set_device(gpu)\n","\n","    pad_idx = vocab_tgt[\"<blank>\"]\n","    d_model = 512\n","    print(\"Got to this point(1)!!!\")\n","    model = make_model(len(vocab_src), len(vocab_tgt), N=6)\n","    print(\"Got to this point(2)!!!\")\n","    model.cuda(gpu)\n","    print(\"Got to this point(3)!!!\")\n","    module = model\n","    print(\"Got to this point(4)!!!\")\n","    is_main_process = True\n","    if is_distributed:\n","        dist.init_process_group(\n","            \"nccl\", init_method=\"env://\", rank=gpu, world_size=ngpus_per_node\n","        )\n","        model = DDP(model, device_ids=[gpu])\n","        module = model.module\n","        is_main_process = gpu == 0\n","\n","    criterion = LabelSmoothing(\n","        size=len(vocab_tgt), padding_idx=pad_idx, smoothing=0.1\n","    )\n","    criterion.cuda(gpu)\n","    print(\"Got to this point(5)!!!\")\n","    #############################\n","    ## PROBLEM IS HERE BELOW!  ##\n","    #############################\n","    train_dataloader, valid_dataloader = create_dataloaders(\n","        gpu,\n","        vocab_src,\n","        vocab_tgt,\n","        spacy_de,\n","        spacy_en,\n","        batch_size=config[\"batch_size\"] // ngpus_per_node,\n","        max_padding=config[\"max_padding\"],\n","        is_distributed=is_distributed,\n","    )\n","    print(\"Got to this point(6)!!!\")\n","    optimizer = torch.optim.Adam(\n","        model.parameters(), lr=config[\"base_lr\"], betas=(0.9, 0.98), eps=1e-9\n","    )\n","    lr_scheduler = LambdaLR(\n","        optimizer=optimizer,\n","        lr_lambda=lambda step: rate(\n","            step, d_model, factor=1, warmup=config[\"warmup\"]\n","        ),\n","    )\n","    train_state = TrainState()\n","    for epoch in range(config[\"num_epochs\"]):\n","        if is_distributed:\n","            train_dataloader.sampler.set_epoch(epoch)\n","            valid_dataloader.sampler.set_epoch(epoch)\n","\n","        model.train()\n","        print(f\"[GPU{gpu}] Epoch {epoch} Training ====\", flush=True)\n","        _, train_state = run_epoch(\n","            (Batch(b[0], b[1], pad_idx) for b in train_dataloader),\n","            model,\n","            SimpleLossCompute(module.generator, criterion),\n","            optimizer,\n","            lr_scheduler,\n","            mode=\"train+log\",\n","            accum_iter=config[\"accum_iter\"],\n","            train_state=train_state,\n","        )\n","\n","        GPUtil.showUtilization()\n","        if is_main_process:\n","            file_path = \"%s%.2d.pt\" % (config[\"file_prefix\"], epoch)\n","            torch.save(module.state_dict(), file_path)\n","        torch.cuda.empty_cache()\n","\n","        print(f\"[GPU{gpu}] Epoch {epoch} Validation ====\", flush=True)\n","        model.eval()\n","        sloss = run_epoch(\n","            (Batch(b[0], b[1], pad_idx) for b in valid_dataloader),\n","            model,\n","            SimpleLossCompute(module.generator, criterion),\n","            DummyOptimizer(),\n","            DummyScheduler(),\n","            mode=\"eval\",\n","        )\n","        print(sloss)\n","        torch.cuda.empty_cache()\n","\n","    if is_main_process:\n","        file_path = \"%sfinal.pt\" % config[\"file_prefix\"]\n","        torch.save(module.state_dict(), file_path)\n","\n","\n","def train_distributed_model(vocab_src, vocab_tgt, spacy_de, spacy_en, config):\n","    from the_annotated_transformer import train_worker\n","\n","    ngpus = torch.cuda.device_count()\n","    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n","    os.environ[\"MASTER_PORT\"] = \"12356\"\n","    print(f\"Number of GPUs detected: {ngpus}\")\n","    print(\"Spawning training processes ...\")\n","    mp.spawn(\n","        train_worker,\n","        nprocs=ngpus,\n","        args=(ngpus, vocab_src, vocab_tgt, spacy_de, spacy_en, config, True),\n","    )\n","\n","\n","def train_model(vocab_src, vocab_tgt, spacy_de, spacy_en, config):\n","    if config[\"distributed\"]:\n","        train_distributed_model(\n","            vocab_src, vocab_tgt, spacy_de, spacy_en, config\n","        )\n","    else:\n","        train_worker(\n","            0, 1, vocab_src, vocab_tgt, spacy_de, spacy_en, config, False\n","        )\n","\n","\n","def load_trained_model():\n","    config = {\n","        \"batch_size\": 1,\n","        \"distributed\": False,\n","        \"num_epochs\": 8,\n","        \"accum_iter\": 10,\n","        \"base_lr\": 1.0,\n","        \"max_padding\": 72,\n","        \"warmup\": 3000,\n","        \"file_prefix\": \"multi30k_model_\",\n","    }\n","    model_path = \"multi30k_model_final.pt\"\n","\n","    print(\"tokenizer sample output: \")\n","    itos = vocab_tgt.get_itos()\n","    for index, token in enumerate(itos):\n","        print(index, token)\n","\n","    if not exists(model_path):\n","        train_model(vocab_src, vocab_tgt, spacy_de, spacy_en, config)\n","\n","    model = make_model(len(vocab_src), len(vocab_tgt), N=6)\n","    model.load_state_dict(torch.load(\"multi30k_model_final.pt\"))\n","    return model\n","\n","\n","if is_interactive_notebook():\n","\n","    model = load_trained_model()"],"metadata":{"id":"skiS2QUTCLpn","executionInfo":{"status":"error","timestamp":1723345837351,"user_tz":-480,"elapsed":412,"user":{"displayName":"fengguoying85@163.com","userId":"03322301898888393442"}},"colab":{"base_uri":"https://localhost:8080/","height":662},"outputId":"bbac563e-3eec-4228-f8f9-d766c91d6389"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["0 <s>\n","1 </s>\n","2 <blank>\n","3 <unk>\n","4 the\n","5 ,\n","6 a\n","7 of\n","8 \n","\n","9 .\n","10 in\n","11 session\n","12 you\n","13 '\n","14 I\n","15 have\n","16 on\n","17 that\n","18 this\n","19 to\n"]},{"output_type":"error","ename":"ZeroDivisionError","evalue":"division by zero","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-70-63a9384c113a>\u001b[0m in \u001b[0;36m<cell line: 154>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_interactive_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_trained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-70-63a9384c113a>\u001b[0m in \u001b[0;36mload_trained_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0;36m4\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_tgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspacy_de\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspacy_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"]}]},{"cell_type":"code","source":["if False:\n","    model.src_embed[0].lut.weight = model.tgt_embeddings[0].lut.weight\n","    model.generator.lut.weight = model.tgt_embed[0].lut.weight"],"metadata":{"id":"zwAFp7XrCL7d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def average(model, models):\n","    \"Average models into model\"\n","    for ps in zip(*[m.params() for m in [model] + models]):\n","        ps[0].copy_(torch.sum(*ps[1:]) / len(ps[1:]))"],"metadata":{"id":"7opuH2NGChoB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def check_outputs(\n","    valid_dataloader,\n","    model,\n","    vocab_src,\n","    vocab_tgt,\n","    n_examples=15,\n","    pad_idx=2,\n","    eos_string=\"</s>\",\n","):\n","    results = [()] * n_examples\n","    for idx in range(n_examples):\n","        print(\"\\nExample %d ========\\n\" % idx)\n","        b = next(iter(valid_dataloader))\n","        rb = Batch(b[0], b[1], pad_idx)\n","        greedy_decode(model, rb.src, rb.src_mask, 64, 0)[0]\n","\n","        src_tokens = [\n","            vocab_src.get_itos()[x] for x in rb.src[0] if x != pad_idx\n","        ]\n","        tgt_tokens = [\n","            vocab_tgt.get_itos()[x] for x in rb.tgt[0] if x != pad_idx\n","        ]\n","\n","        print(\n","            \"Source Text (Input)        : \"\n","            + \" \".join(src_tokens).replace(\"\\n\", \"\")\n","        )\n","        print(\n","            \"Target Text (Ground Truth) : \"\n","            + \" \".join(tgt_tokens).replace(\"\\n\", \"\")\n","        )\n","        model_out = greedy_decode(model, rb.src, rb.src_mask, 72, 0)[0]\n","        model_txt = (\n","            \" \".join(\n","                [vocab_tgt.get_itos()[x] for x in model_out if x != pad_idx]\n","            ).split(eos_string, 1)[0]\n","            + eos_string\n","        )\n","        print(\"Model Output               : \" + model_txt.replace(\"\\n\", \"\"))\n","        results[idx] = (rb, src_tokens, tgt_tokens, model_out, model_txt)\n","    return results\n","\n","\n","def run_model_example(n_examples=5):\n","    global vocab_src, vocab_tgt, spacy_de, spacy_en\n","\n","    print(\"Preparing Data ...\")\n","    _, valid_dataloader = create_dataloaders(\n","        torch.device(\"cpu\"),\n","        vocab_src,\n","        vocab_tgt,\n","        spacy_de,\n","        spacy_en,\n","        batch_size=1,\n","        is_distributed=False,\n","    )\n","\n","    print(\"Loading Trained Model ...\")\n","\n","    model = make_model(len(vocab_src), len(vocab_tgt), N=6)\n","    model.load_state_dict(\n","        torch.load(\"multi30k_model_final.pt\", map_location=torch.device(\"cpu\"))\n","    )\n","\n","    print(\"Checking Model Outputs:\")\n","    example_data = check_outputs(\n","        valid_dataloader, model, vocab_src, vocab_tgt, n_examples=n_examples\n","    )\n","    return model, example_data\n","\n","\n","# execute_example(run_model_example)"],"metadata":{"id":"uBe6bSWMCh6n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def mtx2df(m, max_row, max_col, row_tokens, col_tokens):\n","    \"convert a dense matrix to a data frame with row and column indices\"\n","    return pd.DataFrame(\n","        [\n","            (\n","                r,\n","                c,\n","                float(m[r, c]),\n","                \"%.3d %s\"\n","                % (r, row_tokens[r] if len(row_tokens) > r else \"<blank>\"),\n","                \"%.3d %s\"\n","                % (c, col_tokens[c] if len(col_tokens) > c else \"<blank>\"),\n","            )\n","            for r in range(m.shape[0])\n","            for c in range(m.shape[1])\n","            if r < max_row and c < max_col\n","        ],\n","        # if float(m[r,c]) != 0 and r < max_row and c < max_col],\n","        columns=[\"row\", \"column\", \"value\", \"row_token\", \"col_token\"],\n","    )\n","\n","\n","def attn_map(attn, layer, head, row_tokens, col_tokens, max_dim=30):\n","    df = mtx2df(\n","        attn[0, head].data,\n","        max_dim,\n","        max_dim,\n","        row_tokens,\n","        col_tokens,\n","    )\n","    return (\n","        alt.Chart(data=df)\n","        .mark_rect()\n","        .encode(\n","            x=alt.X(\"col_token\", axis=alt.Axis(title=\"\")),\n","            y=alt.Y(\"row_token\", axis=alt.Axis(title=\"\")),\n","            color=\"value\",\n","            tooltip=[\"row\", \"column\", \"value\", \"row_token\", \"col_token\"],\n","        )\n","        .properties(height=400, width=400)\n","        .interactive()\n","    )"],"metadata":{"id":"4DGsjJLLCiFA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_encoder(model, layer):\n","    return model.encoder.layers[layer].self_attn.attn\n","\n","\n","def get_decoder_self(model, layer):\n","    return model.decoder.layers[layer].self_attn.attn\n","\n","\n","def get_decoder_src(model, layer):\n","    return model.decoder.layers[layer].src_attn.attn\n","\n","\n","def visualize_layer(model, layer, getter_fn, ntokens, row_tokens, col_tokens):\n","    # ntokens = last_example[0].ntokens\n","    attn = getter_fn(model, layer)\n","    n_heads = attn.shape[1]\n","    charts = [\n","        attn_map(\n","            attn,\n","            0,\n","            h,\n","            row_tokens=row_tokens,\n","            col_tokens=col_tokens,\n","            max_dim=ntokens,\n","        )\n","        for h in range(n_heads)\n","    ]\n","    assert n_heads == 8\n","    return alt.vconcat(\n","        charts[0]\n","        # | charts[1]\n","        | charts[2]\n","        # | charts[3]\n","        | charts[4]\n","        # | charts[5]\n","        | charts[6]\n","        # | charts[7]\n","        # layer + 1 due to 0-indexing\n","    ).properties(title=\"Layer %d\" % (layer + 1))"],"metadata":{"id":"sqWS1mmYCywF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def viz_encoder_self():\n","    model, example_data = run_model_example(n_examples=1)\n","    example = example_data[\n","        len(example_data) - 1\n","    ]  # batch object for the final example\n","\n","    layer_viz = [\n","        visualize_layer(\n","            model, layer, get_encoder, len(example[1]), example[1], example[1]\n","        )\n","        for layer in range(6)\n","    ]\n","    return alt.hconcat(\n","        layer_viz[0]\n","        # & layer_viz[1]\n","        & layer_viz[2]\n","        # & layer_viz[3]\n","        & layer_viz[4]\n","        # & layer_viz[5]\n","    )\n","\n","\n","show_example(viz_encoder_self)"],"metadata":{"id":"9EO4_jhXC3sY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def viz_decoder_self():\n","    model, example_data = run_model_example(n_examples=1)\n","    example = example_data[len(example_data) - 1]\n","\n","    layer_viz = [\n","        visualize_layer(\n","            model,\n","            layer,\n","            get_decoder_self,\n","            len(example[1]),\n","            example[1],\n","            example[1],\n","        )\n","        for layer in range(6)\n","    ]\n","    return alt.hconcat(\n","        layer_viz[0]\n","        & layer_viz[1]\n","        & layer_viz[2]\n","        & layer_viz[3]\n","        & layer_viz[4]\n","        & layer_viz[5]\n","    )\n","\n","\n","show_example(viz_decoder_self)"],"metadata":{"id":"tqed9ADwDAd8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def viz_decoder_src():\n","    model, example_data = run_model_example(n_examples=1)\n","    example = example_data[len(example_data) - 1]\n","\n","    layer_viz = [\n","        visualize_layer(\n","            model,\n","            layer,\n","            get_decoder_src,\n","            max(len(example[1]), len(example[2])),\n","            example[1],\n","            example[2],\n","        )\n","        for layer in range(6)\n","    ]\n","    return alt.hconcat(\n","        layer_viz[0]\n","        & layer_viz[1]\n","        & layer_viz[2]\n","        & layer_viz[3]\n","        & layer_viz[4]\n","        & layer_viz[5]\n","    )\n","\n","\n","show_example(viz_decoder_src)"],"metadata":{"id":"B5lArPKdDHVZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# The following cells have been added for the purpose of troubleshooting.\n","\n","I have resolved all of the problems.   I am leaving the cell below for reference.\n","\n"],"metadata":{"id":"eidRGwbDndT9"}},{"cell_type":"markdown","source":["Experimenting with this site as a work around for the necessary vocabulary.\n","\n","Perhaps this site could be helpful:\n","\n","See https://github.com/PetrochukM/PyTorch-NLP/blob/master/torchnlp/datasets/multi30k.py\n","\n"],"metadata":{"id":"J5SqWBAfaLv2"}},{"cell_type":"code","source":[],"metadata":{"id":"48ujWlirdCeE"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["FXSobPzveYTN"],"provenance":[{"file_id":"131hohvAKRqzHg4K3_68UGL4oi4SGOB45","timestamp":1722151785768},{"file_id":"1RGT4BTopmBIsJEV1EGnLstCY4tXN8Qwg","timestamp":1653171002523}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}